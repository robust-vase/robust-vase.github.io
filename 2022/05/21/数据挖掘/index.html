<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>数据挖掘 | 花瓶的博客</title><meta name="author" content="花瓶"><meta name="copyright" content="花瓶"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="前言 写在前面 虽然这门课学习了机器学习的相关知识，但是只是基于sklearn包scikit-learn中文社区进行调参，并没有手动实践机器学习的相关算法。只能说是对机器学习这门课有一个大概的初步认识，加之老师讲课的内容比较基础，关于机器学习的知识大多都是B站自学的。(其实就是上课没听过课而已) 书籍采用的是李航版本的《统计学习方法》，B站上有很多教程，所以不推荐硬啃书，看视频消化的更快。视频链接">
<meta property="og:type" content="article">
<meta property="og:title" content="数据挖掘">
<meta property="og:url" content="http://example.com/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/index.html">
<meta property="og:site_name" content="花瓶的博客">
<meta property="og:description" content="前言 写在前面 虽然这门课学习了机器学习的相关知识，但是只是基于sklearn包scikit-learn中文社区进行调参，并没有手动实践机器学习的相关算法。只能说是对机器学习这门课有一个大概的初步认识，加之老师讲课的内容比较基础，关于机器学习的知识大多都是B站自学的。(其实就是上课没听过课而已) 书籍采用的是李航版本的《统计学习方法》，B站上有很多教程，所以不推荐硬啃书，看视频消化的更快。视频链接">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img/The_Nightwatch.jpg">
<meta property="article:published_time" content="2022-05-21T03:39:19.000Z">
<meta property="article:modified_time" content="2023-07-30T15:30:01.000Z">
<meta property="article:author" content="花瓶">
<meta property="article:tag" content="大数据">
<meta property="article:tag" content="Python">
<meta property="article:tag" content="sklearn">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/The_Nightwatch.jpg"><link rel="shortcut icon" href="/img/kele.png"><link rel="canonical" href="http://example.com/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: {"limitDay":1500,"position":"top","messagePrev":"这篇文章已经有","messageNext":"未更新，花瓶里没有保鲜剂"},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":250},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"bottom-left"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '数据挖掘',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-07-30 23:30:01'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/icon.css"><link rel="stylesheet" href="/css/custom.css"><script src="https://cdn.staticfile.org/jquery/3.6.3/jquery.min.js"></script><script async data-pjax src="/js/map.js"></script><!-- hexo injector head_end start --><link rel="stylesheet" href="https://unpkg.zhimg.com/hexo-butterfly-footer-beautify@1.0.0/lib/runtime.min.css" media="print" onload="this.media='all'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body><script>window.paceOptions = {
  restartOnPushState: false
}

document.addEventListener('pjax:send', () => {
  Pace.restart()
})
</script><link rel="stylesheet" href="/css/pace.css"/><script src="https://cdn.jsdelivr.net/npm/pace-js/pace.min.js"></script><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/img/John_King.webp" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">15</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">18</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw iconfont icon-shouye"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw iconfont icon-wenzhang"></i><span> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw iconfont icon-shijian"></i><span> 时间轴</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw iconfont icon-biaoqian"></i><span> 标签</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw iconfont icon-fenlei"></i><span> 分类</span></a></li><li><a class="site-page child" href="/charts/"><i class="fa-fw iconfont icon-tongji"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw iconfont icon-shejiao"></i><span> 社交</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw iconfont icon-lianjie"></i><span> 友情链接</span></a></li><li><a class="site-page child" href="/daily/"><i class="fa-fw iconfont icon-xiaoxi"></i><span> 日常说说</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/knowme/"><i class="fa-fw iconfont icon-mingpian"></i><span> 认识花瓶</span></a></div><div class="menus_item"><a class="site-page" href="/comments/"><i class="fa-fw iconfont icon-liuyanban"></i><span> 留言板</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/The_Nightwatch.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="花瓶的博客"><span class="site-name">花瓶的博客</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw iconfont icon-shouye"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw iconfont icon-wenzhang"></i><span> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw iconfont icon-shijian"></i><span> 时间轴</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw iconfont icon-biaoqian"></i><span> 标签</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw iconfont icon-fenlei"></i><span> 分类</span></a></li><li><a class="site-page child" href="/charts/"><i class="fa-fw iconfont icon-tongji"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw iconfont icon-shejiao"></i><span> 社交</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw iconfont icon-lianjie"></i><span> 友情链接</span></a></li><li><a class="site-page child" href="/daily/"><i class="fa-fw iconfont icon-xiaoxi"></i><span> 日常说说</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/knowme/"><i class="fa-fw iconfont icon-mingpian"></i><span> 认识花瓶</span></a></div><div class="menus_item"><a class="site-page" href="/comments/"><i class="fa-fw iconfont icon-liuyanban"></i><span> 留言板</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">数据挖掘</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-05-21T03:39:19.000Z" title="发表于 2022-05-21 11:39:19">2022-05-21</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-07-30T15:30:01.000Z" title="更新于 2023-07-30 23:30:01">2023-07-30</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%BB%9F%E8%AE%A1/">统计</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">10.3k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>49分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="数据挖掘"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1>前言</h1>
<h2 id="写在前面-2">写在前面</h2>
<p>虽然这门课学习了机器学习的相关知识，但是只是基于sklearn包<a target="_blank" rel="noopener" href="https://scikit-learn.org.cn/">scikit-learn中文社区</a>进行调参，并没有手动实践机器学习的相关算法。只能说是对机器学习这门课有一个大概的初步认识，加之老师讲课的内容比较基础，关于机器学习的知识大多都是B站自学的。<s>(其实就是上课没听过课而已)</s></p>
<p>书籍采用的是李航版本的《统计学习方法》，B站上有很多教程，所以不推荐硬啃书，看视频消化的更快。视频链接：<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1No4y1o7ac?share_source=copy_web">十分钟机器学习</a></p>
<div align="center" class="aspect-ratio">
    <iframe src="https://www.bilibili.com/video/BV1No4y1o7ac?share_source=copy_web" scrolling="no" border="0" frameborder="no" framespacing="0" high_quality="1" danmaku="1" allowfullscreen="true"> 
    </iframe>
</div>
<p>可能后期会自主编写相关机器学习的代码，从最基本的感知机开始……那都是后话了。</p>
<h2 id="工具">工具</h2>
<p>老师推荐的是Spyder（其实Anaconda里面自带了），但是这里更加推荐的是Pycharm里面的Juypter。</p>
<h2 id="配置Python环境">配置Python环境</h2>
<p>安装虚拟环境</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create -n sklearn python=3.8</span><br></pre></td></tr></table></figure>
<p>激活虚拟环境</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda activate sklearn</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>安装包</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">conda install numpy</span><br><span class="line"></span><br><span class="line">conda install scipy</span><br><span class="line"></span><br><span class="line">conda install scikit-learn</span><br><span class="line"></span><br><span class="line">conda install matplotlib</span><br><span class="line"></span><br><span class="line">conda install seaborn</span><br><span class="line"></span><br><span class="line">conda install pandas</span><br></pre></td></tr></table></figure>
<p>展示安装包</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip list</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/image-20220521135617838.png" alt="环境展示"></p>
<h1>数据预处理与数据分析</h1>
<h2 id="导入库与数据">导入库与数据</h2>
<p>导入库</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> display</span><br></pre></td></tr></table></figure>
<p>导入数据集
<strong>注：数据的excel文件需要放在.ipynb文件的同一目录下</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data = pd.read_csv(<span class="string">&#x27;train.csv&#x27;</span>)</span><br><span class="line">data</span><br></pre></td></tr></table></figure>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>Braund, Mr. Owen Harris</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>A/5 21171</td>
      <td>7.2500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>PC 17599</td>
      <td>71.2833</td>
      <td>C85</td>
      <td>C</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1</td>
      <td>3</td>
      <td>Heikkinen, Miss. Laina</td>
      <td>female</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>STON/O2. 3101282</td>
      <td>7.9250</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>
      <td>female</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>113803</td>
      <td>53.1000</td>
      <td>C123</td>
      <td>S</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>0</td>
      <td>3</td>
      <td>Allen, Mr. William Henry</td>
      <td>male</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>373450</td>
      <td>8.0500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>886</th>
      <td>887</td>
      <td>0</td>
      <td>2</td>
      <td>Montvila, Rev. Juozas</td>
      <td>male</td>
      <td>27.0</td>
      <td>0</td>
      <td>0</td>
      <td>211536</td>
      <td>13.0000</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>887</th>
      <td>888</td>
      <td>1</td>
      <td>1</td>
      <td>Graham, Miss. Margaret Edith</td>
      <td>female</td>
      <td>19.0</td>
      <td>0</td>
      <td>0</td>
      <td>112053</td>
      <td>30.0000</td>
      <td>B42</td>
      <td>S</td>
    </tr>
    <tr>
      <th>888</th>
      <td>889</td>
      <td>0</td>
      <td>3</td>
      <td>Johnston, Miss. Catherine Helen "Carrie"</td>
      <td>female</td>
      <td>NaN</td>
      <td>1</td>
      <td>2</td>
      <td>W./C. 6607</td>
      <td>23.4500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>889</th>
      <td>890</td>
      <td>1</td>
      <td>1</td>
      <td>Behr, Mr. Karl Howell</td>
      <td>male</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>111369</td>
      <td>30.0000</td>
      <td>C148</td>
      <td>C</td>
    </tr>
    <tr>
      <th>890</th>
      <td>891</td>
      <td>0</td>
      <td>3</td>
      <td>Dooley, Mr. Patrick</td>
      <td>male</td>
      <td>32.0</td>
      <td>0</td>
      <td>0</td>
      <td>370376</td>
      <td>7.7500</td>
      <td>NaN</td>
      <td>Q</td>
    </tr>
  </tbody>
</table>
<p>891 rows × 12 columns</p>
</div>
<p>概括性度量数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.describe()</span><br></pre></td></tr></table></figure>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Fare</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>891.000000</td>
      <td>891.000000</td>
      <td>891.000000</td>
      <td>714.000000</td>
      <td>891.000000</td>
      <td>891.000000</td>
      <td>891.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>446.000000</td>
      <td>0.383838</td>
      <td>2.308642</td>
      <td>29.699118</td>
      <td>0.523008</td>
      <td>0.381594</td>
      <td>32.204208</td>
    </tr>
    <tr>
      <th>std</th>
      <td>257.353842</td>
      <td>0.486592</td>
      <td>0.836071</td>
      <td>14.526497</td>
      <td>1.102743</td>
      <td>0.806057</td>
      <td>49.693429</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.420000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>223.500000</td>
      <td>0.000000</td>
      <td>2.000000</td>
      <td>20.125000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>7.910400</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>446.000000</td>
      <td>0.000000</td>
      <td>3.000000</td>
      <td>28.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>14.454200</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>668.500000</td>
      <td>1.000000</td>
      <td>3.000000</td>
      <td>38.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>31.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>891.000000</td>
      <td>1.000000</td>
      <td>3.000000</td>
      <td>80.000000</td>
      <td>8.000000</td>
      <td>6.000000</td>
      <td>512.329200</td>
    </tr>
  </tbody>
</table>
</div>
<p>备份数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df = data.copy()</span><br></pre></td></tr></table></figure>
<h2 id="数据处理">数据处理</h2>
<p>字符串数据处理判断标准：若字符串的重复率低于30%，则认定字符串与乘客存活无关</p>
<p>空缺数据处理判断标准：空缺率在20%以上的数据集无意义，空缺率在20%以下的数据集中的空缺数据可以用平均值代替</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.isnull().<span class="built_in">sum</span>(axis=<span class="number">0</span>)/<span class="built_in">len</span>(df)</span><br></pre></td></tr></table></figure>
<pre><code>PassengerId    0.000000
Survived       0.000000
Pclass         0.000000
Name           0.000000
Sex            0.000000
Age            0.198653
SibSp          0.000000
Parch          0.000000
Ticket         0.000000
Fare           0.000000
Cabin          0.771044
Embarked       0.002245
dtype: float64
</code></pre>
<h3 id="性别处理">性别处理</h3>
<p>将男性编号为1，女性编号为0</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">sex_value</span>(<span class="params">sex</span>):</span><br><span class="line">    <span class="keyword">if</span> sex==<span class="string">&#x27;male&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">&#x27;Sex&#x27;</span>]=df[<span class="string">&#x27;Sex&#x27;</span>].apply(<span class="keyword">lambda</span> x:sex_value(x))</span><br></pre></td></tr></table></figure>
<h3 id="姓名处理">姓名处理</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;姓名重复率：&#x27;</span>)</span><br><span class="line">(<span class="built_in">len</span>(df) - df[<span class="string">&#x27;Name&#x27;</span>].unique().shape[<span class="number">0</span>])/<span class="built_in">len</span>(df)</span><br></pre></td></tr></table></figure>
<pre><code>姓名重复率：0.0
</code></pre>
<h3 id="船票编号处理">船票编号处理</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;船票编号重复率：&#x27;</span>)</span><br><span class="line">(<span class="built_in">len</span>(df) - df[<span class="string">&#x27;Ticket&#x27;</span>].unique().shape[<span class="number">0</span>])/<span class="built_in">len</span>(df)</span><br></pre></td></tr></table></figure>
<pre><code>船票编号重复率：0.2356902356902357
</code></pre>
<h3 id="乘客乘船码头处理">乘客乘船码头处理</h3>
<p>乘客乘船码头重复率</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;乘客登船码头重复率：&#x27;</span>)</span><br><span class="line">(<span class="built_in">len</span>(df) - df[<span class="string">&#x27;Embarked&#x27;</span>].unique().shape[<span class="number">0</span>])/<span class="built_in">len</span>(df)</span><br></pre></td></tr></table></figure>
<pre><code>乘客登船码头重复率：0.9955106621773289
</code></pre>
<p>删去缺失数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df = df.dropna(axis=<span class="number">0</span>,subset=[<span class="string">&#x27;Embarked&#x27;</span>])</span><br><span class="line">df.reset_index(drop=<span class="literal">True</span>, inplace=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>将字符串对应成编号</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">&#x27;Embarked&#x27;</span>] =df[<span class="string">&#x27;Embarked&#x27;</span>].replace(<span class="string">&#x27;C&#x27;</span>, <span class="number">1</span>)</span><br><span class="line">df[<span class="string">&#x27;Embarked&#x27;</span>] =df[<span class="string">&#x27;Embarked&#x27;</span>].replace(<span class="string">&#x27;Q&#x27;</span>, <span class="number">2</span>)</span><br><span class="line">df[<span class="string">&#x27;Embarked&#x27;</span>] =df[<span class="string">&#x27;Embarked&#x27;</span>].replace(<span class="string">&#x27;S&#x27;</span>, <span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<h3 id="年龄处理">年龄处理</h3>
<p><strong>随机森林回归填补缺失值</strong></p>
<p>导入机器学习中的随机森林回归（RandomForestRegressor）方法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</span><br></pre></td></tr></table></figure>
<p>不含缺失值的其他所有列</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df_full=df.drop(labels=[<span class="string">&#x27;Age&#x27;</span>,<span class="string">&#x27;PassengerId&#x27;</span>,<span class="string">&#x27;Name&#x27;</span>,<span class="string">&#x27;Ticket&#x27;</span>,<span class="string">&#x27;Cabin&#x27;</span>],axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>含缺失值的那一列</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df_nan=df.loc[:,<span class="string">&#x27;Age&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>区别测试集与训练集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df_nan.notnull()</span><br></pre></td></tr></table></figure>
<pre><code>0       True
1       True
2       True
3       True
4       True
       ...  
884     True
885     True
886    False
887     True
888     True
Name: Age, Length: 889, dtype: bool
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df_nan.isnull()</span><br></pre></td></tr></table></figure>
<pre><code>0      False
1      False
2      False
3      False
4      False
       ...  
884    False
885    False
886     True
887    False
888    False
Name: Age, Length: 889, dtype: bool
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Xtrain = df_full[df_nan.notnull()]</span><br><span class="line">Ytrain = df_nan[df_nan.notnull()]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Ytest = df_nan[df_nan.isnull()]</span><br><span class="line">Xtest = df_full.iloc[Ytest.index]</span><br></pre></td></tr></table></figure>
<p>随机森林训练及预测</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rfc = RandomForestRegressor(n_estimators=<span class="number">100</span>)</span><br><span class="line">rfc = rfc.fit(Xtrain, Ytrain)</span><br><span class="line">Ypredict = rfc.predict(Xtest)</span><br></pre></td></tr></table></figure>
<p>预测结果四舍五入</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Ypredict_round = Ypredict.<span class="built_in">round</span>()</span><br></pre></td></tr></table></figure>
<p>填入预测数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df_nan[df_nan.isnull()] = Ypredict_round</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df</span><br></pre></td></tr></table></figure>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>Braund, Mr. Owen Harris</td>
      <td>1</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>A/5 21171</td>
      <td>7.2500</td>
      <td>NaN</td>
      <td>3</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
      <td>0</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>PC 17599</td>
      <td>71.2833</td>
      <td>C85</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1</td>
      <td>3</td>
      <td>Heikkinen, Miss. Laina</td>
      <td>0</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>STON/O2. 3101282</td>
      <td>7.9250</td>
      <td>NaN</td>
      <td>3</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>
      <td>0</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>113803</td>
      <td>53.1000</td>
      <td>C123</td>
      <td>3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>0</td>
      <td>3</td>
      <td>Allen, Mr. William Henry</td>
      <td>1</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>373450</td>
      <td>8.0500</td>
      <td>NaN</td>
      <td>3</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>884</th>
      <td>887</td>
      <td>0</td>
      <td>2</td>
      <td>Montvila, Rev. Juozas</td>
      <td>1</td>
      <td>27.0</td>
      <td>0</td>
      <td>0</td>
      <td>211536</td>
      <td>13.0000</td>
      <td>NaN</td>
      <td>3</td>
    </tr>
    <tr>
      <th>885</th>
      <td>888</td>
      <td>1</td>
      <td>1</td>
      <td>Graham, Miss. Margaret Edith</td>
      <td>0</td>
      <td>19.0</td>
      <td>0</td>
      <td>0</td>
      <td>112053</td>
      <td>30.0000</td>
      <td>B42</td>
      <td>3</td>
    </tr>
    <tr>
      <th>886</th>
      <td>889</td>
      <td>0</td>
      <td>3</td>
      <td>Johnston, Miss. Catherine Helen "Carrie"</td>
      <td>0</td>
      <td>23.0</td>
      <td>1</td>
      <td>2</td>
      <td>W./C. 6607</td>
      <td>23.4500</td>
      <td>NaN</td>
      <td>3</td>
    </tr>
    <tr>
      <th>887</th>
      <td>890</td>
      <td>1</td>
      <td>1</td>
      <td>Behr, Mr. Karl Howell</td>
      <td>1</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>111369</td>
      <td>30.0000</td>
      <td>C148</td>
      <td>1</td>
    </tr>
    <tr>
      <th>888</th>
      <td>891</td>
      <td>0</td>
      <td>3</td>
      <td>Dooley, Mr. Patrick</td>
      <td>1</td>
      <td>32.0</td>
      <td>0</td>
      <td>0</td>
      <td>370376</td>
      <td>7.7500</td>
      <td>NaN</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
<p>889 rows × 12 columns</p>
</div>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">col_x = [<span class="string">&#x27;Pclass&#x27;</span>,<span class="string">&#x27;Sex&#x27;</span>,<span class="string">&#x27;Age&#x27;</span>,<span class="string">&#x27;SibSp&#x27;</span>,<span class="string">&#x27;Parch&#x27;</span>,<span class="string">&#x27;Fare&#x27;</span>,<span class="string">&#x27;Embarked&#x27;</span>]</span><br><span class="line">col_y = [<span class="string">&#x27;Survived&#x27;</span>]</span><br><span class="line">X = pd.DataFrame(df,columns = col_x)</span><br><span class="line">y=pd.DataFrame(df,columns = col_y)</span><br></pre></td></tr></table></figure>
<p>测试集处理</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data_predict = pd.read_csv(<span class="string">&#x27;test.csv&#x27;</span>)</span><br><span class="line">df_predict = data_predict.copy()</span><br><span class="line">df_predict</span><br></pre></td></tr></table></figure>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>892</td>
      <td>3</td>
      <td>Kelly, Mr. James</td>
      <td>male</td>
      <td>34.5</td>
      <td>0</td>
      <td>0</td>
      <td>330911</td>
      <td>7.8292</td>
      <td>NaN</td>
      <td>Q</td>
    </tr>
    <tr>
      <th>1</th>
      <td>893</td>
      <td>3</td>
      <td>Wilkes, Mrs. James (Ellen Needs)</td>
      <td>female</td>
      <td>47.0</td>
      <td>1</td>
      <td>0</td>
      <td>363272</td>
      <td>7.0000</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>2</th>
      <td>894</td>
      <td>2</td>
      <td>Myles, Mr. Thomas Francis</td>
      <td>male</td>
      <td>62.0</td>
      <td>0</td>
      <td>0</td>
      <td>240276</td>
      <td>9.6875</td>
      <td>NaN</td>
      <td>Q</td>
    </tr>
    <tr>
      <th>3</th>
      <td>895</td>
      <td>3</td>
      <td>Wirz, Mr. Albert</td>
      <td>male</td>
      <td>27.0</td>
      <td>0</td>
      <td>0</td>
      <td>315154</td>
      <td>8.6625</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>4</th>
      <td>896</td>
      <td>3</td>
      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>
      <td>female</td>
      <td>22.0</td>
      <td>1</td>
      <td>1</td>
      <td>3101298</td>
      <td>12.2875</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>413</th>
      <td>1305</td>
      <td>3</td>
      <td>Spector, Mr. Woolf</td>
      <td>male</td>
      <td>NaN</td>
      <td>0</td>
      <td>0</td>
      <td>A.5. 3236</td>
      <td>8.0500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>414</th>
      <td>1306</td>
      <td>1</td>
      <td>Oliva y Ocana, Dona. Fermina</td>
      <td>female</td>
      <td>39.0</td>
      <td>0</td>
      <td>0</td>
      <td>PC 17758</td>
      <td>108.9000</td>
      <td>C105</td>
      <td>C</td>
    </tr>
    <tr>
      <th>415</th>
      <td>1307</td>
      <td>3</td>
      <td>Saether, Mr. Simon Sivertsen</td>
      <td>male</td>
      <td>38.5</td>
      <td>0</td>
      <td>0</td>
      <td>SOTON/O.Q. 3101262</td>
      <td>7.2500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>416</th>
      <td>1308</td>
      <td>3</td>
      <td>Ware, Mr. Frederick</td>
      <td>male</td>
      <td>NaN</td>
      <td>0</td>
      <td>0</td>
      <td>359309</td>
      <td>8.0500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>417</th>
      <td>1309</td>
      <td>3</td>
      <td>Peter, Master. Michael J</td>
      <td>male</td>
      <td>NaN</td>
      <td>1</td>
      <td>1</td>
      <td>2668</td>
      <td>22.3583</td>
      <td>NaN</td>
      <td>C</td>
    </tr>
  </tbody>
</table>
<p>418 rows × 11 columns</p>
</div>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df_predict.isnull().<span class="built_in">sum</span>(axis=<span class="number">0</span>)/<span class="built_in">len</span>(df_predict)</span><br></pre></td></tr></table></figure>
<pre><code>PassengerId    0.000000
Pclass         0.000000
Name           0.000000
Sex            0.000000
Age            0.205742
SibSp          0.000000
Parch          0.000000
Ticket         0.000000
Fare           0.002392
Cabin          0.782297
Embarked       0.000000
dtype: float64
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">df_predict = df_predict.dropna(axis=<span class="number">0</span>,subset=[<span class="string">&#x27;Fare&#x27;</span>])</span><br><span class="line">df_predict.reset_index(drop=<span class="literal">True</span>, inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">df_predict[<span class="string">&#x27;Sex&#x27;</span>]=df_predict[<span class="string">&#x27;Sex&#x27;</span>].apply(<span class="keyword">lambda</span> x:sex_value(x))</span><br><span class="line"></span><br><span class="line">df_predict[<span class="string">&#x27;Embarked&#x27;</span>] =df_predict[<span class="string">&#x27;Embarked&#x27;</span>].replace(<span class="string">&#x27;C&#x27;</span>, <span class="number">1</span>)</span><br><span class="line">df_predict[<span class="string">&#x27;Embarked&#x27;</span>] =df_predict[<span class="string">&#x27;Embarked&#x27;</span>].replace(<span class="string">&#x27;Q&#x27;</span>, <span class="number">2</span>)</span><br><span class="line">df_predict[<span class="string">&#x27;Embarked&#x27;</span>] =df_predict[<span class="string">&#x27;Embarked&#x27;</span>].replace(<span class="string">&#x27;S&#x27;</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">age_mean=df_predict[<span class="string">&#x27;Age&#x27;</span>].mean()</span><br><span class="line">df_predict[<span class="string">&#x27;Age&#x27;</span>]=df_predict[<span class="string">&#x27;Age&#x27;</span>].fillna(age_mean)</span><br><span class="line">df_predict[<span class="string">&#x27;Age&#x27;</span>]=df_predict[<span class="string">&#x27;Age&#x27;</span>].<span class="built_in">round</span>()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_predict = pd.DataFrame(df_predict,columns = col_x)</span><br></pre></td></tr></table></figure>
<h2 id="数据分析">数据分析</h2>
<h3 id="统计量分析">统计量分析</h3>
<p>计算均值、方差、标准差 (取了一些有意义的数据)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.DataFrame(&#123;<span class="string">&quot;平均数&quot;</span>:X.mean(),<span class="string">&quot;方差&quot;</span>:X.var(),<span class="string">&quot;标准差&quot;</span>:X.std()&#125;).T</span><br></pre></td></tr></table></figure>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Pclass</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Fare</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>平均数</th>
      <td>2.311586</td>
      <td>0.649044</td>
      <td>29.534499</td>
      <td>0.524184</td>
      <td>0.382452</td>
      <td>32.096681</td>
      <td>2.535433</td>
    </tr>
    <tr>
      <th>方差</th>
      <td>0.696724</td>
      <td>0.228042</td>
      <td>189.760852</td>
      <td>1.218164</td>
      <td>0.650863</td>
      <td>2469.841935</td>
      <td>0.627403</td>
    </tr>
    <tr>
      <th>标准差</th>
      <td>0.834700</td>
      <td>0.477538</td>
      <td>13.775371</td>
      <td>1.103705</td>
      <td>0.806761</td>
      <td>49.697504</td>
      <td>0.792088</td>
    </tr>
  </tbody>
</table>
</div>
<p>偏度与峰度</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.DataFrame(&#123;<span class="string">&#x27;偏度&#x27;</span>: X.skew(), <span class="string">&#x27;峰度&#x27;</span>: X.kurt()&#125;,).T</span><br></pre></td></tr></table></figure>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Pclass</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Fare</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>偏度</th>
      <td>-0.636998</td>
      <td>-0.625625</td>
      <td>0.417878</td>
      <td>3.691058</td>
      <td>2.745160</td>
      <td>4.801440</td>
      <td>-1.261367</td>
    </tr>
    <tr>
      <th>峰度</th>
      <td>-1.269437</td>
      <td>-1.612225</td>
      <td>0.378453</td>
      <td>17.838972</td>
      <td>9.750592</td>
      <td>33.508477</td>
      <td>-0.216100</td>
    </tr>
  </tbody>
</table>
</div>
<p>协方差</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X.cov()</span><br></pre></td></tr></table></figure>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Pclass</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Fare</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Pclass</th>
      <td>0.696724</td>
      <td>0.050918</td>
      <td>-4.453329</td>
      <td>0.075226</td>
      <td>0.011330</td>
      <td>-22.740426</td>
      <td>0.108880</td>
    </tr>
    <tr>
      <th>Sex</th>
      <td>0.050918</td>
      <td>0.228042</td>
      <td>0.965950</td>
      <td>-0.061323</td>
      <td>-0.095355</td>
      <td>-4.270831</td>
      <td>0.041729</td>
    </tr>
    <tr>
      <th>Age</th>
      <td>-4.453329</td>
      <td>0.965950</td>
      <td>189.760852</td>
      <td>-4.765379</td>
      <td>-2.344380</td>
      <td>58.171717</td>
      <td>-0.134675</td>
    </tr>
    <tr>
      <th>SibSp</th>
      <td>0.075226</td>
      <td>-0.061323</td>
      <td>-4.765379</td>
      <td>1.218164</td>
      <td>0.369119</td>
      <td>8.824866</td>
      <td>0.060234</td>
    </tr>
    <tr>
      <th>Parch</th>
      <td>0.011330</td>
      <td>-0.095355</td>
      <td>-2.344380</td>
      <td>0.369119</td>
      <td>0.650863</td>
      <td>8.721729</td>
      <td>0.025848</td>
    </tr>
    <tr>
      <th>Fare</th>
      <td>-22.740426</td>
      <td>-4.270831</td>
      <td>58.171717</td>
      <td>8.824866</td>
      <td>8.721729</td>
      <td>2469.841935</td>
      <td>-8.908691</td>
    </tr>
    <tr>
      <th>Embarked</th>
      <td>0.108880</td>
      <td>0.041729</td>
      <td>-0.134675</td>
      <td>0.060234</td>
      <td>0.025848</td>
      <td>-8.908691</td>
      <td>0.627403</td>
    </tr>
  </tbody>
</table>
</div>
<p>相关矩阵</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X.corr()</span><br></pre></td></tr></table></figure>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Pclass</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Fare</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Pclass</th>
      <td>1.000000</td>
      <td>0.127741</td>
      <td>-0.387303</td>
      <td>0.081656</td>
      <td>0.016824</td>
      <td>-0.548193</td>
      <td>0.164681</td>
    </tr>
    <tr>
      <th>Sex</th>
      <td>0.127741</td>
      <td>1.000000</td>
      <td>0.146840</td>
      <td>-0.116348</td>
      <td>-0.247508</td>
      <td>-0.179958</td>
      <td>0.110320</td>
    </tr>
    <tr>
      <th>Age</th>
      <td>-0.387303</td>
      <td>0.146840</td>
      <td>1.000000</td>
      <td>-0.313430</td>
      <td>-0.210950</td>
      <td>0.084972</td>
      <td>-0.012343</td>
    </tr>
    <tr>
      <th>SibSp</th>
      <td>0.081656</td>
      <td>-0.116348</td>
      <td>-0.313430</td>
      <td>1.000000</td>
      <td>0.414542</td>
      <td>0.160887</td>
      <td>0.068900</td>
    </tr>
    <tr>
      <th>Parch</th>
      <td>0.016824</td>
      <td>-0.247508</td>
      <td>-0.210950</td>
      <td>0.414542</td>
      <td>1.000000</td>
      <td>0.217532</td>
      <td>0.040449</td>
    </tr>
    <tr>
      <th>Fare</th>
      <td>-0.548193</td>
      <td>-0.179958</td>
      <td>0.084972</td>
      <td>0.160887</td>
      <td>0.217532</td>
      <td>1.000000</td>
      <td>-0.226311</td>
    </tr>
    <tr>
      <th>Embarked</th>
      <td>0.164681</td>
      <td>0.110320</td>
      <td>-0.012343</td>
      <td>0.068900</td>
      <td>0.040449</td>
      <td>-0.226311</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>
<h3 id="图表分析">图表分析</h3>
<p>统计图</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure()</span><br><span class="line">sns.countplot(data=df, x=<span class="string">&#x27;Survived&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>​    <img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/output_63_0-165310504609844.png" alt="统计图"></p>
<p>箱型图</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure()</span><br><span class="line">sns.boxplot(data=df, y=<span class="string">&#x27;Age&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/output_65_0-165310508438745.png" alt="箱型图"></p>
<p>全体箱型图</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure()</span><br><span class="line">sns.boxplot(data=df)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/output_67_0-165310511357746.png" alt="全体箱型图"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure()</span><br><span class="line">sns.boxplot(data=df,y=<span class="string">&#x27;SibSp&#x27;</span>, x=<span class="string">&#x27;Parch&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/output_68_0-165310512308247.png" alt="全体箱型图"></p>
<p>散点图</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure()</span><br><span class="line">sns.stripplot(data=df, x=<span class="string">&#x27;Sex&#x27;</span>, y=<span class="string">&#x27;Embarked&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/output_70_0-165310516574349.png" alt="散点图"></p>
<p>直方图</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure()</span><br><span class="line">sns.histplot(df, x=<span class="string">&#x27;Age&#x27;</span>, kde=<span class="literal">True</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/output_72_0-165310518335850.png" alt="直方图"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure()</span><br><span class="line">sns.histplot(df, x=<span class="string">&#x27;Fare&#x27;</span>, hue=<span class="string">&#x27;Survived&#x27;</span>, kde=<span class="literal">True</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/output_73_0-165310520448051.png" alt="直方图"></p>
<p>散点图</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure()</span><br><span class="line">sns.scatterplot(data=df, x=<span class="string">&#x27;SibSp&#x27;</span>, y=<span class="string">&#x27;Parch&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/output_75_0-165310540860552.png" alt="散点图"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure()</span><br><span class="line">sns.scatterplot(data=df, x=<span class="string">&#x27;SibSp&#x27;</span>, y=<span class="string">&#x27;Parch&#x27;</span>, hue=<span class="string">&#x27;Survived&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/output_76_0-165310542236153.png" alt="散点图"></p>
<p>联合分布图</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure()</span><br><span class="line">sns.pairplot(X)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<pre><code>&lt;Figure size 432x288 with 0 Axes&gt;
</code></pre>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/output_78_1-165310545516254.png" alt="联合分布图"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure()</span><br><span class="line">sns.pairplot(X, diag_kind=<span class="string">&#x27;kde&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<pre><code>&lt;Figure size 432x288 with 0 Axes&gt;
</code></pre>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/output_79_1-165310546719355.png" alt="联合分布图"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure()</span><br><span class="line">sns.pairplot(df, hue=<span class="string">&#x27;Survived&#x27;</span>, diag_kind=<span class="string">&#x27;kde&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<pre><code>&lt;Figure size 432x288 with 0 Axes&gt;
</code></pre>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/output_80_1-165310547892556.png" alt="联合分布图"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure()</span><br><span class="line">g = sns.jointplot(data=df, x=<span class="string">&#x27;Age&#x27;</span>, y=<span class="string">&#x27;Fare&#x27;</span>, hue=<span class="string">&#x27;Survived&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<pre><code>&lt;Figure size 432x288 with 0 Axes&gt;
</code></pre>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/output_81_1-165310548964557.png" alt="双变量图"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure()</span><br><span class="line">sns.jointplot(data=df, x=<span class="string">&#x27;Age&#x27;</span>, y=<span class="string">&#x27;Fare&#x27;</span>, hue=<span class="string">&#x27;Survived&#x27;</span>, kind=<span class="string">&#x27;kde&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<pre><code>&lt;Figure size 432x288 with 0 Axes&gt;
</code></pre>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/output_82_1-165310550416258.png" alt="双变量图"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure()</span><br><span class="line">g = sns.jointplot(data=df, x=<span class="string">&#x27;SibSp&#x27;</span>, y=<span class="string">&#x27;Parch&#x27;</span>, hue=<span class="string">&#x27;Survived&#x27;</span>)</span><br><span class="line">g.plot_joint(sns.kdeplot)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<pre><code>&lt;Figure size 432x288 with 0 Axes&gt;
</code></pre>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/output_83_1-165310553283159.png" alt="双变量图"></p>
<p>核密度估计</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure()</span><br><span class="line">sns.kdeplot(data=df, x=<span class="string">&#x27;Fare&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/output_85_0-165310553951960.png" alt="核密度估计图"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure()</span><br><span class="line">sns.kdeplot(data=df, x=<span class="string">&#x27;SibSp&#x27;</span>, y=<span class="string">&#x27;Parch&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/output_86_0-165310554856761.png" alt="核密度估计图"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure()</span><br><span class="line">sns.kdeplot(data=df, x=<span class="string">&#x27;SibSp&#x27;</span>, y=<span class="string">&#x27;Parch&#x27;</span>, fill=<span class="literal">True</span>, cbar=<span class="literal">True</span>, cmap=<span class="string">&#x27;Reds&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/output_87_0-165310555535262.png" alt="核密度估计图"></p>
<p>stats连续型随机变量的公共方法：</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr>
<td>rvs</td>
<td>产生服从指定分布的随机数</td>
</tr>
<tr>
<td>cdf</td>
<td>累计分布函数</td>
</tr>
<tr>
<td>pdf</td>
<td>概率密度函数</td>
</tr>
<tr>
<td>sf</td>
<td>残存函数（1-CDF）</td>
</tr>
<tr>
<td>ppf</td>
<td>分位点函数（CDF的逆）</td>
</tr>
<tr>
<td>isf</td>
<td>逆残存函数（sf的逆）</td>
</tr>
<tr>
<td>fit</td>
<td>对一组随机取样进行拟合，最大似然估计方法找出最适合取样数据的概率密度函数系数。</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure()</span><br><span class="line">ax = sns.kdeplot(data=df, x=<span class="string">&#x27;Fare&#x27;</span>, label=<span class="string">&#x27;Fare&#x27;</span>)</span><br><span class="line"></span><br><span class="line">xmin, xmax = plt.xlim()</span><br><span class="line">x = np.linspace(xmin, xmax, <span class="number">1000</span>)</span><br><span class="line">mu, std = stats.norm.fit(df[<span class="string">&#x27;Fare&#x27;</span>])</span><br><span class="line">p = stats.norm.pdf(x, mu,std)</span><br><span class="line">ax.plot(x, p, <span class="string">&#x27;r&#x27;</span> , label=<span class="string">&#x27;fit normal&#x27;</span>)</span><br><span class="line">ax.legend()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;fitted mu: <span class="subst">&#123;mu&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;fitted std: <span class="subst">&#123;std&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/output_89_0-165310557158163.png" alt="核密度估计图"></p>
<pre><code>fitted mu: 32.09668087739032
fitted std: 49.669545099689564
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> [<span class="string">&#x27;Pclass&#x27;</span>,  <span class="string">&#x27;Sex&#x27;</span>,<span class="string">&#x27;SibSp&#x27;</span>,<span class="string">&#x27;Parch&#x27;</span>]:</span><br><span class="line">    sns.kdeplot(data=df, x=i, label=i)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/output_90_0-165310558128164.png" alt="核密度估计图"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure()</span><br><span class="line">s = df[<span class="string">&#x27;Survived&#x27;</span>].astype(<span class="string">&quot;category&quot;</span>)</span><br><span class="line">cates = s.cat.categories</span><br><span class="line"><span class="keyword">for</span> cat <span class="keyword">in</span> cates:</span><br><span class="line">        df1 = df[df[<span class="string">&#x27;Survived&#x27;</span>] == cat]</span><br><span class="line">        sns.kdeplot(data=df1, x=<span class="string">&#x27;Fare&#x27;</span>, label=cat)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>​<br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/output_91_0-165310559077265.png" alt="核密度估计图">​</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">s = df[<span class="string">&#x27;Survived&#x27;</span>].astype(<span class="string">&quot;category&quot;</span>)</span><br><span class="line">cates = s.cat.categories</span><br><span class="line">fig,axs = plt.subplots(<span class="number">1</span>, <span class="built_in">len</span>(cates), figsize=(<span class="built_in">len</span>(cates) * <span class="number">6</span>, <span class="number">4</span>))</span><br><span class="line"><span class="keyword">for</span> col,cat <span class="keyword">in</span> <span class="built_in">enumerate</span>(cates):</span><br><span class="line">    ax = axs[col]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> [<span class="string">&#x27;Pclass&#x27;</span>,  <span class="string">&#x27;Sex&#x27;</span>,<span class="string">&#x27;SibSp&#x27;</span>,<span class="string">&#x27;Parch&#x27;</span>]:</span><br><span class="line">        df1 = df[df[<span class="string">&#x27;Survived&#x27;</span>] == cat]</span><br><span class="line">        sns.kdeplot(data=df1, x=i, label=i, ax=ax)</span><br><span class="line">    ax.set_title(cat)</span><br><span class="line">    ax.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/output_92_0-165310583064766.png" alt="核密度估计图"></p>
<p>平行坐标系</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pd.plotting.parallel_coordinates(pd.concat([X,y],axis=<span class="number">1</span>), <span class="string">&#x27;Survived&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/output_94_0-165310584869367.png" alt="平行坐标系"></p>
<p>热力图</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">c = X.corr()</span><br><span class="line">display(c)</span><br><span class="line">sns.heatmap(c, cmap=<span class="string">&#x27;jet&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Pclass</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Fare</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Pclass</th>
      <td>1.000000</td>
      <td>0.127741</td>
      <td>-0.387303</td>
      <td>0.081656</td>
      <td>0.016824</td>
      <td>-0.548193</td>
      <td>0.164681</td>
    </tr>
    <tr>
      <th>Sex</th>
      <td>0.127741</td>
      <td>1.000000</td>
      <td>0.146840</td>
      <td>-0.116348</td>
      <td>-0.247508</td>
      <td>-0.179958</td>
      <td>0.110320</td>
    </tr>
    <tr>
      <th>Age</th>
      <td>-0.387303</td>
      <td>0.146840</td>
      <td>1.000000</td>
      <td>-0.313430</td>
      <td>-0.210950</td>
      <td>0.084972</td>
      <td>-0.012343</td>
    </tr>
    <tr>
      <th>SibSp</th>
      <td>0.081656</td>
      <td>-0.116348</td>
      <td>-0.313430</td>
      <td>1.000000</td>
      <td>0.414542</td>
      <td>0.160887</td>
      <td>0.068900</td>
    </tr>
    <tr>
      <th>Parch</th>
      <td>0.016824</td>
      <td>-0.247508</td>
      <td>-0.210950</td>
      <td>0.414542</td>
      <td>1.000000</td>
      <td>0.217532</td>
      <td>0.040449</td>
    </tr>
    <tr>
      <th>Fare</th>
      <td>-0.548193</td>
      <td>-0.179958</td>
      <td>0.084972</td>
      <td>0.160887</td>
      <td>0.217532</td>
      <td>1.000000</td>
      <td>-0.226311</td>
    </tr>
    <tr>
      <th>Embarked</th>
      <td>0.164681</td>
      <td>0.110320</td>
      <td>-0.012343</td>
      <td>0.068900</td>
      <td>0.040449</td>
      <td>-0.226311</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/output_96_1-165310588370468.png" alt="热力图"></p>
<h1>分类模型</h1>
<h2 id="决策树模型">决策树模型</h2>
<p>导入决策树模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> tree</span><br></pre></td></tr></table></figure>
<p>决策树模型训练</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">xtrain,xtest,ytrain,ytest = train_test_split(X, y,test_size=<span class="number">0.3</span>)</span><br><span class="line">clf = tree.DecisionTreeClassifier()</span><br><span class="line">clf = clf.fit(xtrain,ytrain)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;准确率:&#x27;</span>, clf.score(xtest,ytest))</span><br></pre></td></tr></table></figure>
<pre><code>准确率: 0.7940074906367042
</code></pre>
<p>超参数优化</p>
<table>
<thead>
<tr>
<th style="text-align:center">参数</th>
<th style="text-align:center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><strong>criterion</strong></td>
<td style="text-align:center"><strong>{“gini”, “entropy”}, default=”gini”</strong> 这个参数是用来选择使用何种方法度量树的切分质量的。当criterion取值为“gini”时采用 基尼不纯度（Gini impurity）算法构造决策树，当criterion取值为 “entropy” 时采用信息增益（ information gain）算法构造决策树.</td>
</tr>
<tr>
<td style="text-align:center"><strong>splitter</strong></td>
<td style="text-align:center"><strong>{“best”, “random”}, default=”best”</strong> 此参数决定了在每个节点上拆分策略的选择。支持的策略是“best” 选择“最佳拆分策略”， “random” 选择“最佳随机拆分策略”。</td>
</tr>
<tr>
<td style="text-align:center"><strong>max_depth</strong></td>
<td style="text-align:center"><strong>int, default=None</strong> 树的最大深度。如果取值为None,则将所有节点展开，直到所有的叶子都是纯净的或者直到所有叶子都包含少于min_samples_split个样本。</td>
</tr>
<tr>
<td style="text-align:center"><strong>min_samples_split</strong></td>
<td style="text-align:center"><strong>int or float, default=2</strong> 拆分内部节点所需的最少样本数：  <strong>·</strong> 如果取值 int , 则将<code>min_samples_split</code>视为最小值。 <strong>·</strong> 如果为float，则<code>min_samples_split</code>是一个分数，而<code>ceil（min_samples_split * n_samples）</code>是每个拆分的最小样本数。  -注释 在版本0.18中更改：增加了分数形式的浮点值。</td>
</tr>
<tr>
<td style="text-align:center"><strong>min_samples_leaf</strong></td>
<td style="text-align:center"><strong>int or float, default=1</strong> 在叶节点处所需的最小样本数。 仅在任何深度的分裂点在左分支和右分支中的每个分支上至少留有<code>min_samples_leaf</code>个训练样本时，才考虑。 这可能具有平滑模型的效果，尤其是在回归中。  <strong>·</strong> 如果为int，则将<code>min_samples_leaf</code>视为最小值 <strong>·</strong> 如果为float，则<code>min_samples_leaf</code>是一个分数，而<code>ceil（min_samples_leaf * n_samples）</code>是每个节点的最小样本数。  - 注释： 在版本0.18中发生了更改：添加了分数形式的浮点值。</td>
</tr>
<tr>
<td style="text-align:center"><strong>min_weight_fraction_leaf</strong></td>
<td style="text-align:center"><strong>float, default=0.0</strong> 在所有叶节点处（所有输入样本）的权重总和中的最小加权分数。 如果未提供<code>sample_weight</code>，则样本的权重相等。</td>
</tr>
<tr>
<td style="text-align:center"><strong>max_features</strong></td>
<td style="text-align:center"><strong>int, float or {“auto”, “sqrt”, “log2”}, default=None</strong> 寻找最佳分割时要考虑的特征数量： <strong>-</strong> 如果为<code>int</code>，则在每次拆分时考虑<code>max_features</code>功能。 <strong>-</strong> 如果为<code>float</code>，则<code>max_features</code>是一个分数，而<code>int（max_features * n_features）</code>是每个分割处的特征数量。 <strong>-</strong> 如果为<code>“auto”</code>，则<code>max_features = sqrt（n_features）</code>。 <strong>-</strong> 如果为<code>“sqrt”</code>，则<code>max_features = sqrt（n_features）</code>。 <strong>-</strong> 如果为<code>“log2”</code>，则<code>max_features = log2（n_features）</code>。 <strong>-</strong> 如果为<code>None</code>，则<code>max_features = n_features</code>。  注意：直到找到至少一个有效的节点样本分区，分割的搜索才会停止，即使它需要有效检查的特征数量多于<code>max_features</code>也是如此。</td>
</tr>
<tr>
<td style="text-align:center"><strong>random_state</strong></td>
<td style="text-align:center"><strong>int, RandomState instance, default=None</strong> 此参数用来控制估计器的随机性。即使分割器设置为“最佳”，这些特征也总是在每个分割中随机排列。当<code>max_features &lt;n_features</code>时，该算法将在每个拆分中随机选择<code>max_features</code>，然后再在其中找到最佳拆分。但是，即使<code>max_features = n_features</code>，找到的最佳分割也可能因不同的运行而有所不同。 就是这种情况，如果标准的改进对于几个拆分而言是相同的，并且必须随机选择一个拆分。 为了在拟合过程中获得确定性的行为，<code>random_state</code>必须固定为整数。 有关详细信息，请参见词汇表。</td>
</tr>
<tr>
<td style="text-align:center"><strong>max_leaf_nodes</strong></td>
<td style="text-align:center"><strong>int, default=None</strong> 优先以最佳方式生成带有<code>max_leaf_nodes</code>的树。 最佳节点定义为不纯度的相对减少。 如果为None，则叶节点数不受限制。</td>
</tr>
<tr>
<td style="text-align:center"><strong>min_impurity_decrease</strong></td>
<td style="text-align:center"><strong>float, default=0.0</strong> 如果节点分裂会导致不纯度的减少大于或等于该值，则该节点将被分裂。  加权不纯度减少方程如下： <code>N_t / N * (impurity - N_t_R / N_t * right_impurity</code> <code>- N_t_L / N_t * left_impurity)</code> 其中<code>N</code>是样本总数，<code>N_t</code>是当前节点上的样本数，<code>N_t_L</code>是左子节点中的样本数，<code>N_t_R</code>是右子节点中的样本数。  如果给<code>sample_weight</code>传了值，则<code>N , N_t , N_t_R</code> 和 <code>N_t_L</code>均指加权总和。  在 0.19 版新增 。</td>
</tr>
<tr>
<td style="text-align:center"><strong>min_impurity_split</strong></td>
<td style="text-align:center"><strong>float, default=0</strong> 树模型停止生长的阈值。如果节点的不纯度高于阈值，则该节点将分裂，否则为叶节点。  警告： 从版本0.19开始被弃用:<code>min_impurity_split</code>在0.19中被弃用，转而支持<code>min_impurity_decrease</code>。<code>min_impurity_split</code>的默认值在0.23中从<code>1e-7</code>更改为<code>0</code>，在0.25中将被删除。使用<code>min_impurity_decrease</code>代替。</td>
</tr>
<tr>
<td style="text-align:center"><strong>class_weight</strong></td>
<td style="text-align:center"><strong>dict, list of dict or “balanced”, default=None</strong> 以<code>&#123;class_label: weight&#125;</code>的形式表示与类别关联的权重。如果取值None,所有分类的权重为1。对于多输出问题，可以按照y的列的顺序提供一个字典列表。  注意多输出(包括多标签) ，应在其自己的字典中为每一列的每个类别定义权重。例如：对于四分类多标签问题， 权重应为[{0：1、1：1：1]，{0：1、1：5}，{0：1、1：1：1}，{0：1、1： 1}]，而不是[{1：1}，{2：5}，{3：1}，{4：1}]。  “平衡”模式使用y的值自动将权重与输入数据中的类频率成反比地调整为<code>n_samples /（n_classes * np.bincount（y））</code>。  对于多输出，y的每一列的权重将相乘。  请注意，如果指定了<code>sample_weight</code>，则这些权重将与<code>sample_weight</code>（通过<code>fit</code>方法传递）相乘。</td>
</tr>
<tr>
<td style="text-align:center"><strong>presort</strong></td>
<td style="text-align:center"><strong>deprecated, default=’deprecated’</strong> 此参数已弃用，并将在v0.24中删除。  注意：从0.22版开始已弃用。</td>
</tr>
<tr>
<td style="text-align:center"><strong>ccp_alpha</strong></td>
<td style="text-align:center"><strong>non-negative float, default=0.0</strong> 用于最小化成本复杂性修剪的复杂性参数。 将选择成本复杂度最大且小于ccp_alpha的子树。 默认情况下，不执行修剪。 有关详细信息，请参见最小成本复杂性修剪。</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedKFold</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">clf = tree.DecisionTreeClassifier()</span><br><span class="line">parameters = &#123;</span><br><span class="line">    <span class="string">&#x27;criterion&#x27;</span>: [<span class="string">&#x27;entropy&#x27;</span>, <span class="string">&#x27;gini&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;max_leaf_nodes&#x27;</span>: np.arange(<span class="number">2</span>, <span class="number">9</span>),</span><br><span class="line">    <span class="string">&#x27;max_depth&#x27;</span>: [<span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">8</span>, <span class="number">10</span>, <span class="number">12</span>],</span><br><span class="line">    <span class="string">&#x27;min_impurity_decrease&#x27;</span>: [<span class="number">0</span>, <span class="number">0.02</span>, <span class="number">0.04</span>, <span class="number">0.06</span>, <span class="number">0.08</span>, <span class="number">0.1</span>],</span><br><span class="line">&#125;</span><br><span class="line">skf = StratifiedKFold(n_splits=<span class="number">100</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line">clf_search = GridSearchCV(clf, parameters, cv=skf, scoring=<span class="string">&#x27;accuracy&#x27;</span>, n_jobs=-<span class="number">1</span>)</span><br><span class="line">clf_search.fit(X, y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;最优参数:&#x27;</span>,clf_search.best_params_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;最优分数:&#x27;</span>,clf_search.best_score_)</span><br></pre></td></tr></table></figure>
<pre><code>最优参数: &#123;'criterion': 'entropy', 'max_depth': 4, 'max_leaf_nodes': 8, 'min_impurity_decrease': 0&#125;
最优分数: 0.8226388888888888
</code></pre>
<p>决策树模型平均准确度</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scores = cross_val_score(clf_search.best_estimator_, X, y, cv=<span class="number">6</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;平均得分:&#x27;</span>, np.mean(scores))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;得分:&#x27;</span>, scores)</span><br></pre></td></tr></table></figure>
<pre><code>平均得分: 0.8155420521192333
得分: [0.79865772 0.81081081 0.85810811 0.78378378 0.7972973  0.84459459]
</code></pre>
<p>画图</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> pydotplus</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">clf = clf.fit(X,y)</span><br><span class="line">dot_data = tree.export_graphviz(clf_search.best_estimator_,filled=<span class="literal">True</span>, rounded=<span class="literal">True</span>,special_characters=<span class="literal">True</span>)</span><br><span class="line">graph = pydotplus.graph_from_dot_data(dot_data)</span><br><span class="line">Image(graph.create_png())</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/output_113_0-165310594035169.png" alt="决策树"></p>
<p>测试集预测</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> openpyxl</span><br><span class="line">ypred = clf_search.best_estimator_.predict(X_predict)</span><br></pre></td></tr></table></figure>
<p>输出预测结果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ytestId = pd.DataFrame(df_predict,columns = [<span class="string">&#x27;PassengerId&#x27;</span>])</span><br><span class="line">ytest=pd.DataFrame(ypred)</span><br><span class="line">ytest=ytest.rename(columns=&#123;<span class="string">&quot;Survived&quot;</span>:<span class="string">&#x27;PredictSurvived&#x27;</span>&#125;)</span><br><span class="line">result=ytestId.join(ytest)</span><br><span class="line">result.to_excel(<span class="string">&#x27;决策树预测.xlsx&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="人工神经网络">人工神经网络</h2>
<p>导入模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neural_network <span class="keyword">import</span> MLPClassifier</span><br></pre></td></tr></table></figure>
<p>标准化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scaler = StandardScaler()</span><br><span class="line">scaler.fit(X)</span><br><span class="line">X_scaler = scaler.transform(X)</span><br></pre></td></tr></table></figure>
<p>人工神经网络模型训练</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">X_train,X_test,Y_train,Y_test=train_test_split(X_scaler,y,test_size=<span class="number">0.3</span>)</span><br><span class="line">mlp = MLPClassifier()</span><br><span class="line">mlp = mlp.fit(X_train,Y_train)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;准确率:&#x27;</span>, mlp.score(X_test,Y_test))</span><br></pre></td></tr></table></figure>
<pre><code>准确率: 0.7865168539325843
</code></pre>
<p>超参数优化</p>
<table>
<thead>
<tr>
<th style="text-align:center">参数</th>
<th style="text-align:center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><strong>hidden_layer_sizes</strong></td>
<td style="text-align:center"><strong>tuple, length = n_layers - 2, default=(100,)</strong> 第i个元素代表第i个隐藏层中的神经元数量。</td>
</tr>
<tr>
<td style="text-align:center"><strong>activation</strong></td>
<td style="text-align:center"><strong>{‘identity’, ‘logistic’, ‘tanh’, ‘relu’}, default=’relu’</strong> 隐藏层的激活函数。  - ‘identity’，无操作激活，用于实现线性瓶颈，返回f(x)= x - ‘logistic’,logistic Sigmoid函数，返回f(x)= 1 / (1 + exp(x))。 - ‘tanh’,双曲tan函数，返回f(x)= tanh(x)。 - ‘relu’,整流线性单位函数，返回f(x)= max(0，x)</td>
</tr>
<tr>
<td style="text-align:center"><strong>solver</strong></td>
<td style="text-align:center"><strong>{‘lbfgs’, ‘sgd’, ‘adam’}, default=’adam’</strong> 权重优化的求解器。  - “ lbfgs”是quasi-Newton方法族的优化程序。 - “ sgd”是指随机梯度下降。 - “ adam”是指Kingma，Diederik和Jimmy Ba提出的基于随机梯度的优化器  注意：就训练时间和验证准确率而言，默认求解器“ adam”在相对较大的数据集（具有数千个训练样本或更多）上的效果很好。但是，对于小型数据集，“ lbfgs”可以收敛得更快并且性能更好。</td>
</tr>
<tr>
<td style="text-align:center"><strong>alpha</strong></td>
<td style="text-align:center"><strong>float, default=0.0001</strong> L2惩罚（正则项）参数。</td>
</tr>
<tr>
<td style="text-align:center"><strong>batch_size</strong></td>
<td style="text-align:center"><strong>int, default=’auto’</strong> 随机优化器的小批次的大小。如果求解器为“ lbfgs”，则分类器将不使用小批次批处理。设为“自动”时，<code>batch_size=min(200, n_samples)</code></td>
</tr>
<tr>
<td style="text-align:center"><strong>learning_rate</strong></td>
<td style="text-align:center"><strong>{‘constant’, ‘invscaling’, ‘adaptive’}, default=’constant’</strong> 权重更新的学习速率表。  - ’ constant ‘是一个恒定的学习速率，由’ learning_rate_init '给出。 - “invscaling”通过使用“power_t”的缩放逆指数，逐步降低在每个时间步长“t”上的学习率。effective_learning_rate = learning_rate_init / pow(t, power_t) - 只要训练损失持续减少，‘adaptive’将学习率保持在‘learning_rate_init’不变。每次连续两个epoch不能减少至少tol的训练损失，或者如果“early_stop”开启，不能增加至少tol的验证分数，则当前学习率要除以5。  仅在<code>solver='sgd'</code>时使用。</td>
</tr>
<tr>
<td style="text-align:center"><strong>learning_rate_init</strong></td>
<td style="text-align:center"><strong>double, default=0.001</strong> 使用的初始学习率。它控制更新权重的步长。仅在Solver ='sgd’或’adam’时使用。</td>
</tr>
<tr>
<td style="text-align:center"><strong>power_t</strong></td>
<td style="text-align:center"><strong>double, default=0.5</strong> 反比例学习率的指数。当learning_rate设置为“ invscaling”时，它用于更新有效学习率。仅在Solver ='sgd’时使用。</td>
</tr>
<tr>
<td style="text-align:center"><strong>max_iter</strong></td>
<td style="text-align:center"><strong>int, default=200</strong> 最大迭代次数。求解器迭代直到收敛（由“ tol”决定）或这个迭代次数。对于随机求解器（“ sgd”，“ adam”），请注意，这决定时期数（每个数据点将使用多少次），而不是梯度步数。</td>
</tr>
<tr>
<td style="text-align:center"><strong>shuffle</strong></td>
<td style="text-align:center"><strong>bool, default=True</strong> 是否在每次迭代中对样本进行打乱。仅在Solver ='sgd’或’adam’时使用。</td>
</tr>
<tr>
<td style="text-align:center"><strong>random_state</strong></td>
<td style="text-align:center"><strong>int, RandomState instance, default=None</strong> 决定用于权重和偏差初始化的随机数生成，如果使用了提前停止，则切分测试集和训练集，并在solver ='sgd’或’adam’时批量采样。在多个函数调用之间传递一个int值以获得可重复的结果。请参阅<a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/glossary.html#term-random-state">词汇表</a>。</td>
</tr>
<tr>
<td style="text-align:center"><strong>tol</strong></td>
<td style="text-align:center"><strong>float, default=1e-4</strong> 优化公差。当<code>n_iter_no_change</code>连续迭代的损失或分数没有通过至少<code>tol</code>得到改善时，除非将<code>learning_rate</code>设置为‘adaptive’，否则将认为达到收敛并停止训练。</td>
</tr>
<tr>
<td style="text-align:center"><strong>verbose</strong></td>
<td style="text-align:center"><strong>bool, default=False</strong> 是否将进度消息打印到标准输出。</td>
</tr>
<tr>
<td style="text-align:center"><strong>warm_start</strong></td>
<td style="text-align:center"><strong>bool, default=False</strong> 设置为True时，请重用上一个调用的解决方案以拟合初始化，否则，只需擦除以前的解决方案即可。请参阅<a target="_blank" rel="noopener" href="http://scikit-learn.org.cn/lists/91.html#%E5%8F%82%E6%95%B0">词汇表</a>。</td>
</tr>
<tr>
<td style="text-align:center"><strong>momentum</strong></td>
<td style="text-align:center"><strong>float, default=0.9</strong> 梯度下降更新的动量。应该在0到1之间。仅在solver ='sgd’时使用。</td>
</tr>
<tr>
<td style="text-align:center"><strong>nesterovs_momentum</strong></td>
<td style="text-align:center"><strong>boolean, default=True</strong> 是否使用内Nesterov的动量。仅在Solver ='sgd’且momentum&gt; 0时使用。</td>
</tr>
<tr>
<td style="text-align:center"><strong>early_stopping</strong></td>
<td style="text-align:center"><strong>bool, default=False</strong> 当验证准确率没有提高时，是否使用提前停止来终止训练。如果设置为true，它将自动预留10％的训练数据作为验证，并在<code>n_iter_no_change</code>连续几个时期，验证准确率没有提高至少tol时终止训练 。除多标签设置外，这个切分是分层的。仅在Solver ='sgd’或’adam’时有效</td>
</tr>
<tr>
<td style="text-align:center"><strong>validation_fraction</strong></td>
<td style="text-align:center"><strong>float, default=0.1</strong> 预留的训练数据比例作为提前停止的验证集。必须在0到1之间。仅当early_stopping为True时使用</td>
</tr>
<tr>
<td style="text-align:center"><strong>beta_1</strong></td>
<td style="text-align:center"><strong>float, default=0.9</strong> adam第一矩向量估计的指数衰减率，应在[0，1）范围内。仅在solver ='adam’时使用</td>
</tr>
<tr>
<td style="text-align:center"><strong>beta_2</strong></td>
<td style="text-align:center"><strong>float, default=0.999</strong> adam第二矩向量估计的指数衰减率，应在[0，1）范围内。仅在solver ='adam’时使用</td>
</tr>
<tr>
<td style="text-align:center"><strong>epsilon</strong></td>
<td style="text-align:center"><strong>float, default=1e-8</strong> adam中数值稳定性的值。仅在solver ='adam’时使用</td>
</tr>
<tr>
<td style="text-align:center"><strong>n_iter_no_change</strong></td>
<td style="text-align:center"><strong>int, default=10</strong> 不满足<code>tol</code>改进的最大时期数。仅在Solver ='sgd’或’adam’时有效  <em>0.20版中的新功能。</em></td>
</tr>
<tr>
<td style="text-align:center"><strong>max_fun</strong></td>
<td style="text-align:center"><strong>int, default=15000</strong> 仅在Solver ='lbfgs’时使用。损失函数调用的最大次数。求解器迭代直到收敛（由“ tol”确定），迭代次数达到max_iter或这个损失函数调用的次数。请注意，损失函数调用的次数将大于或等于<code>MLPClassifier</code>的迭代次数。  <em>0.22版中的新功能。</em></td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedShuffleSplit,GridSearchCV</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">mlp = MLPClassifier()</span><br><span class="line">parameters = [</span><br><span class="line">    &#123;<span class="string">&#x27;activation&#x27;</span>: [<span class="string">&#x27;logistic&#x27;</span>, <span class="string">&#x27;relu&#x27;</span>, <span class="string">&#x27;tanh&#x27;</span>],<span class="string">&#x27;alpha&#x27;</span>: np.logspace(-<span class="number">5</span>, <span class="number">3</span>, <span class="number">5</span>),<span class="string">&#x27;hidden_layer_sizes&#x27;</span>: [ (<span class="number">100</span>,), (<span class="number">120</span>,), (<span class="number">140</span>,), (<span class="number">160</span>,), (<span class="number">180</span>,), (<span class="number">200</span>,)]&#125;,</span><br><span class="line">    &#123;<span class="string">&#x27;activation&#x27;</span>: [<span class="string">&#x27;relu&#x27;</span>, <span class="string">&#x27;tanh&#x27;</span>],<span class="string">&#x27;alpha&#x27;</span>: np.logspace(-<span class="number">5</span>, <span class="number">3</span>, <span class="number">5</span>),<span class="string">&#x27;hidden_layer_sizes&#x27;</span>: [ (<span class="number">100</span>,<span class="number">100</span>), (<span class="number">120</span>,<span class="number">120</span>), (<span class="number">140</span>,<span class="number">140</span>), (<span class="number">160</span>,<span class="number">160</span>), (<span class="number">180</span>,<span class="number">180</span>), (<span class="number">200</span>,<span class="number">200</span>)]&#125;,</span><br><span class="line">    &#123;<span class="string">&#x27;activation&#x27;</span>: [<span class="string">&#x27;relu&#x27;</span>],<span class="string">&#x27;alpha&#x27;</span>: np.logspace(-<span class="number">5</span>, <span class="number">3</span>, <span class="number">5</span>),<span class="string">&#x27;hidden_layer_sizes&#x27;</span>: [ (<span class="number">100</span>,<span class="number">100</span>,<span class="number">100</span>), (<span class="number">120</span>,<span class="number">120</span>,<span class="number">120</span>), (<span class="number">140</span>,<span class="number">140</span>,<span class="number">140</span>), (<span class="number">160</span>,<span class="number">160</span>,<span class="number">160</span>), (<span class="number">180</span>,<span class="number">180</span>,<span class="number">180</span>), (<span class="number">200</span>,<span class="number">200</span>,<span class="number">200</span>)]&#125;</span><br><span class="line">]</span><br><span class="line">skf = StratifiedShuffleSplit(n_splits = <span class="number">20</span>, test_size=<span class="number">0.2</span>, random_state=<span class="number">1</span>)</span><br><span class="line">mlp_search = GridSearchCV(mlp, parameters, cv=skf, scoring=<span class="string">&#x27;accuracy&#x27;</span>, n_jobs=-<span class="number">1</span>)</span><br><span class="line">mlp_search.fit(X_scaler, y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;最优参数:&#x27;</span>,mlp_search.best_params_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;最优分数:&#x27;</span>,mlp_search.best_score_)</span><br></pre></td></tr></table></figure>
<pre><code>最优参数: &#123;'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (140,)&#125;
最优分数: 0.8384831460674158
</code></pre>
<p>多指标评估</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> make_scorer</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_validate</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#scoring = [&#x27;accuracy&#x27;, &#x27;precision&#x27;]</span></span><br><span class="line">scoring = &#123;<span class="string">&#x27;accuracy&#x27;</span>: make_scorer(accuracy_score),<span class="string">&#x27;prec&#x27;</span>: <span class="string">&#x27;precision&#x27;</span>&#125;</span><br><span class="line">cv_results = cross_validate(mlp_search.best_estimator_.fit(X_scaler, y), X_scaler, y, cv=<span class="number">5</span>, scoring=scoring)</span><br><span class="line"><span class="built_in">print</span>(cv_results)</span><br></pre></td></tr></table></figure>
<pre><code>&#123;'fit_time': array([0.80034709, 0.7290976 , 0.75559878, 0.75425696, 0.73791957]), 'score_time': array([0.00095391, 0.00199413, 0.00202894, 0.00202847, 0.0009973 ]), 'test_accuracy': array([0.82022472, 0.82022472, 0.84269663, 0.80337079, 0.86440678]), 'test_prec': array([0.82142857, 0.82142857, 0.84482759, 0.85106383, 0.84375   ])&#125;
</code></pre>
<p>绘制ROC曲线</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> plot_roc_curve</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.rcParams[<span class="string">&#x27;figure.dpi&#x27;</span>] = <span class="number">300</span> <span class="comment">#分辨率</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>] <span class="comment">#用来正常显示中文标签</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span> <span class="comment">#用来正常显示负号</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">X_train, X_test, y_train, y_test = train_test_split(X_scaler, y, random_state=<span class="number">42</span>)</span><br><span class="line">mlp_search.best_estimator_.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">roc_disp = plot_roc_curve(mlp_search.best_estimator_, X_test, y_test)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/output_136_1-165310601047370.png" alt="ROC曲线"></p>
<p>测试集预测</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> openpyxl</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scaler_predict = StandardScaler()</span><br><span class="line">scaler_predict.fit(X_predict)</span><br><span class="line">X_predict_scaler = scaler_predict.transform(X_predict)</span><br><span class="line">ypred = mlp_search.best_estimator_.predict(X_predict_scaler)</span><br><span class="line">ypred</span><br></pre></td></tr></table></figure>
<pre><code>array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1,
       1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1,
       1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,
       1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1,
       0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,
       0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,
       0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,
       0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0,
       0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1,
       0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0,
       0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,
       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,
       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,
       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0,
       0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1,
       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,
       1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0],
      dtype=int64)
</code></pre>
<p>输出预测结果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ytestId = pd.DataFrame(df_predict, columns=[<span class="string">&#x27;PassengerId&#x27;</span>])</span><br><span class="line">ytest = pd.DataFrame(ypred)</span><br><span class="line">ytest = ytest.rename(columns=&#123;<span class="string">&quot;Survived&quot;</span>: <span class="string">&#x27;PredictSurvived&#x27;</span>&#125;)</span><br><span class="line">result = ytestId.join(ytest)</span><br><span class="line">result.to_excel(<span class="string">&#x27;神经网络预测.xlsx&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="支持向量机">支持向量机</h2>
<p>导入模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br></pre></td></tr></table></figure>
<p>支持向量机模型训练</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> make_pipeline</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">X_train,X_test,Y_train,Y_test=train_test_split(X,y,test_size=<span class="number">0.3</span>)</span><br><span class="line">svms = make_pipeline(StandardScaler(), svm.SVC())</span><br><span class="line">svms = svms.fit(X_train,Y_train)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;准确率:&#x27;</span>, svms.score(X_test,Y_test))</span><br></pre></td></tr></table></figure>
<pre><code>准确率: 0.7902621722846442
</code></pre>
<p>超参数优化</p>
<table>
<thead>
<tr>
<th style="text-align:center">参数</th>
<th style="text-align:center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><strong>C</strong></td>
<td style="text-align:center"><strong>浮点数，默认= 1.0</strong> 正则化参数。正则化的强度与C成反比。必须严格为正。此惩罚系数是l2惩罚系数的平方</td>
</tr>
<tr>
<td style="text-align:center"><strong>kernel</strong></td>
<td style="text-align:center"><strong>{‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’}, 默认=’rbf’</strong> 指定算法中使用的内核类型。它必须是“linear”，“poly”，“rbf”，“sigmoid”，“precomputed”或者“callable”中的一个。如果没有给出，将默认使用“rbf”。如果给定了一个可调用函数，则用它来预先计算核矩阵。该矩阵应为形状数组<code>（n_samples，n_samples）</code></td>
</tr>
<tr>
<td style="text-align:center"><strong>degree</strong></td>
<td style="text-align:center"><strong>整数型，默认=3</strong> 多项式核函数的次数(’ poly ')。将会被其他内核忽略。</td>
</tr>
<tr>
<td style="text-align:center"><strong>gamma</strong></td>
<td style="text-align:center"><strong>浮点数或者{‘scale’, ‘auto’} , 默认=’scale’</strong> 核系数包含‘rbf’, ‘poly’ 和‘sigmoid’ 如果gamma=‘scale’(默认)，则它使用1 / (n_features * X.var())作为gamma的值，如果是auto，则使用1 / n_features。 在0.22版本有改动：默认的gamma从“auto”改为“scale”。</td>
</tr>
<tr>
<td style="text-align:center"><strong>coef0</strong></td>
<td style="text-align:center"><strong>浮点数，默认=0.0</strong> 核函数中的独立项。它只在’ poly ‘和’ sigmoid '中有意义。</td>
</tr>
<tr>
<td style="text-align:center"><strong>shrinking</strong></td>
<td style="text-align:center"><strong>布尔值，默认=True</strong> 是否使用缩小启发式，参见[使用指南](http://scikit-learn.org.cn/view/83.html#1.4.5 实用技巧)</td>
</tr>
<tr>
<td style="text-align:center"><strong>probability</strong></td>
<td style="text-align:center"><strong>布尔值，默认=False</strong> 是否启用概率估计。必须在调用fit之前启用此参数，因为该方法内部使用5折交叉验证，因此会减慢该方法的速度，并且predict_proba可能与dict不一致。更多信息请阅读[使用指南](http://scikit-learn.org.cn/view/83.html#1.4.1 分类)</td>
</tr>
<tr>
<td style="text-align:center"><strong>tol</strong></td>
<td style="text-align:center"><strong>浮点数，默认=1e-3</strong> 残差收敛条件。</td>
</tr>
<tr>
<td style="text-align:center"><strong>cache_size</strong></td>
<td style="text-align:center"><strong>浮点数，默认=200</strong> 指定内核缓存的大小（以MB为单位）。</td>
</tr>
<tr>
<td style="text-align:center"><strong>class_weight</strong></td>
<td style="text-align:center"><strong>{dict, ‘balanced’}, 默认=None</strong> 在SVC中，将类i的参数C设置为class_weight [i] * C。如果没有给出值，则所有类都将设置为单位权重。“balanced”模式使用y的值自动将权重与类频率成反比地调整为<code>n_samples / (n_classes * np.bincount(y))</code></td>
</tr>
<tr>
<td style="text-align:center"><strong>verbose</strong></td>
<td style="text-align:center"><strong>布尔值，默认=False</strong> 是否启用详细输出。请注意，此参数针对liblinear中运行每个进程时设置，如果启用，则可能无法在多线程上下文中正常工作。</td>
</tr>
<tr>
<td style="text-align:center"><strong>max_iter</strong></td>
<td style="text-align:center"><strong>整数型，默认=-1</strong> 对求解器内的迭代进行硬性限制，或者为-1（无限制时）。</td>
</tr>
<tr>
<td style="text-align:center"><strong>decision_function_shape</strong></td>
<td style="text-align:center"><strong>{‘ovo’, ‘ovr’}, 默认=’ovr’</strong> 是否要将返回形状为(n_samples, n_classes)的one-vs-rest (‘ovr’)决策函数应用于其他所有分类器，而在多类别划分中始终使用one-vs-one (‘ovo’)，对于二进制分类，将忽略该参数。 在版本0.19中进行了更改：默认情况下Decision_function_shape为ovr。 0.17版中的新功能：推荐使用Decision_function_shape =‘ovr’。 在0.17版中进行了更改：不建议使用Decision_function_shape ='ovo’和None。</td>
</tr>
<tr>
<td style="text-align:center"><strong>break_ties</strong></td>
<td style="text-align:center"><strong>bool, default=False</strong> 如果为true，decision_function_shape =‘ovr’，并且类数&gt; 2，则预测将根据Decision_function的置信度值打破平局；否则，返回绑定类中的第一类。请注意，与简单的预测相比，打破平局的计算成本较高。 这是0.22版中的新功能。</td>
</tr>
<tr>
<td style="text-align:center"><strong>random_state</strong></td>
<td style="text-align:center"><strong>整数型或RandomState的实例，默认=None</strong> 控制用于数据抽取时的伪随机数生成。当<code>probability</code>为False时将忽略该参数。在多个函数调用之间传递可重复输出的整数值。请参阅<a target="_blank" rel="noopener" href="http://scikit-learn.org.cn/lists/91.html#%E5%8F%82%E6%95%B0">词汇表</a>。</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedShuffleSplit</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scaler = StandardScaler()</span><br><span class="line">scaler.fit(X)</span><br><span class="line">X_scaler = scaler.transform(X)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">svms = svm.SVC()</span><br><span class="line">parameters = &#123;</span><br><span class="line">    <span class="string">&#x27;kernel&#x27;</span>: (<span class="string">&#x27;linear&#x27;</span>, <span class="string">&#x27;poly&#x27;</span>, <span class="string">&#x27;rbf&#x27;</span>, <span class="string">&#x27;sigmoid&#x27;</span>),</span><br><span class="line">    <span class="string">&#x27;C&#x27;</span>: [<span class="number">0.01</span>,<span class="number">0.1</span>,<span class="number">1</span>,<span class="number">10</span>,<span class="number">100</span>],</span><br><span class="line">    <span class="comment">#&#x27;gamma&#x27;: [0.01,0.1,1,10,100],</span></span><br><span class="line">    <span class="comment">#&#x27;class_weight&#x27;:[&#x27;balanced&#x27;, None],</span></span><br><span class="line">&#125;</span><br><span class="line">skf = StratifiedShuffleSplit(n_splits = <span class="number">20</span>, test_size=<span class="number">0.2</span>, random_state=<span class="number">1</span>)</span><br><span class="line">svm_search = GridSearchCV(svms, parameters, cv=skf)</span><br><span class="line">svm_search.fit(X_scaler, y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;最优参数:&#x27;</span>,svm_search.best_params_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;最优分数:&#x27;</span>,svm_search.best_score_)</span><br></pre></td></tr></table></figure>
<pre><code>最优参数: &#123;'C': 1, 'kernel': 'rbf'&#125;
最优分数: 0.8294943820224718
</code></pre>
<p>绘制验证曲线</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> validation_curve</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">param_range = np.logspace(-<span class="number">6</span>, <span class="number">2</span>, <span class="number">8</span>)</span><br><span class="line">train_scores, test_scores = validation_curve(svm.SVC(), X, y, param_name=<span class="string">&quot;gamma&quot;</span>,param_range=param_range, scoring=<span class="string">&quot;accuracy&quot;</span>, n_jobs=<span class="number">1</span>)</span><br><span class="line">train_scores_mean = np.mean(train_scores, axis=<span class="number">1</span>)</span><br><span class="line">train_scores_std = np.std(train_scores, axis=<span class="number">1</span>)</span><br><span class="line">test_scores_mean = np.mean(test_scores, axis=<span class="number">1</span>)</span><br><span class="line">test_scores_std = np.std(test_scores, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&quot;Validation Curve with SVM&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">r&quot;$\gamma$&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Score&quot;</span>)</span><br><span class="line">plt.ylim(<span class="number">0.0</span>, <span class="number">1.1</span>)</span><br><span class="line">lw = <span class="number">2</span></span><br><span class="line">plt.semilogx(param_range, train_scores_mean, label=<span class="string">&quot;Training score&quot;</span>,</span><br><span class="line">             color=<span class="string">&quot;darkorange&quot;</span>, lw=lw)</span><br><span class="line">plt.fill_between(param_range, train_scores_mean - train_scores_std,</span><br><span class="line">                 train_scores_mean + train_scores_std, alpha=<span class="number">0.2</span>,</span><br><span class="line">                 color=<span class="string">&quot;darkorange&quot;</span>, lw=lw)</span><br><span class="line">plt.semilogx(param_range, test_scores_mean, label=<span class="string">&quot;Cross-validation score&quot;</span>,</span><br><span class="line">             color=<span class="string">&quot;navy&quot;</span>, lw=lw)</span><br><span class="line">plt.fill_between(param_range, test_scores_mean - test_scores_std,</span><br><span class="line">                 test_scores_mean + test_scores_std, alpha=<span class="number">0.2</span>,</span><br><span class="line">                 color=<span class="string">&quot;navy&quot;</span>, lw=lw)</span><br><span class="line">plt.legend(loc=<span class="string">&quot;best&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/output_155_1-165310607593871.png" alt="验证曲线"></p>
<p>绘制精确度-召回率曲线</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> average_precision_score</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> precision_recall_curve</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> plot_precision_recall_curve</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.rcParams[<span class="string">&#x27;figure.dpi&#x27;</span>] = <span class="number">300</span> <span class="comment">#分辨率</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>] <span class="comment">#用来正常显示中文标签</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span> <span class="comment">#用来正常显示负号</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">X_train, X_test, y_train, y_test = train_test_split(X_scaler, y,test_size=<span class="number">0.3</span>)</span><br><span class="line">y_score=svm_search.best_estimator_.decision_function(X_test)</span><br><span class="line">average_precision = average_precision_score(y_test, y_score)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;平均精确度分数: &#123;0:0.2f&#125;&#x27;</span>.<span class="built_in">format</span>(average_precision))</span><br></pre></td></tr></table></figure>
<pre><code>平均精确度分数: 0.89
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">disp = plot_precision_recall_curve(svm_search.best_estimator_, X_test, y_test)</span><br><span class="line">disp.ax_.set_title(<span class="string">&#x27;二分类精确度-召回率曲线: &#x27;</span> <span class="string">&#x27;AP=&#123;0:0.2f&#125;&#x27;</span>.<span class="built_in">format</span>(average_precision))</span><br></pre></td></tr></table></figure>
<pre><code>Text(0.5, 1.0, '二分类精确度-召回率曲线: AP=0.89')
</code></pre>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/output_160_2-165310611061372.png" alt="精确度-召回率曲线"></p>
<h2 id="自适应提升法">自适应提升法</h2>
<table>
<thead>
<tr>
<th style="text-align:center">参数</th>
<th style="text-align:center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><strong>base_estimator</strong></td>
<td style="text-align:center"><strong>object, default = None</strong> 建立增强集成的基础估计器。需要支持示例权重，以及适当的<code>classes_</code>和<code>n_classes_</code>属性。如果没有，那么基础估计器是<code>DecisionTreeClassifier(max_depth=1)</code></td>
</tr>
<tr>
<td style="text-align:center"><strong>n_estimators</strong></td>
<td style="text-align:center"><strong>int, default = 50</strong> 终止推进的估计器的最大数目。如果完全拟合，学习过程就会提前停止。</td>
</tr>
<tr>
<td style="text-align:center"><strong>learning_rate</strong></td>
<td style="text-align:center"><strong>float, default = 1</strong> 学习率通过<code>learning_rate</code>缩小每个分类器的贡献程度。<code>learning_rate</code>和<code>n_estimators</code>之间存在权衡关系。</td>
</tr>
<tr>
<td style="text-align:center"><strong>algorithm</strong></td>
<td style="text-align:center"><strong>{‘SAMME’, ‘SAMME.R’}, default = ‘SAMME.R’</strong> 若为&quot;SAMME.R&quot;则使用real bossting算法。<code>base_estimator</code>必须支持类概率的计算。若为SAMME，则使用discrete boosting算法。SAMME.R算法的收敛速度通常比SAMME快，通过更少的增强迭代获得更低的测试误差。</td>
</tr>
<tr>
<td style="text-align:center"><strong>random_state</strong></td>
<td style="text-align:center"><strong>int or RandomState, default = None</strong> 控制每个<code>base_estimator</code>在每个增强迭代中给定的随机种子。因此，仅在<code>base_estimator</code>引入<code>random_state</code>时使用它。在多个函数调用之间传递可重复输出的整数。见<a target="_blank" rel="noopener" href="http://scikit-learn.org.cn/lists/91.html#%E5%8F%82%E6%95%B0">Glossary</a>。</td>
</tr>
</tbody>
</table>
<p>导入模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> AdaBoostClassifier</span><br></pre></td></tr></table></figure>
<p>Adaboost模型训练</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scaler = StandardScaler()</span><br><span class="line">scaler.fit(X)</span><br><span class="line">X_scaler = scaler.transform(X)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">X_train,X_test,Y_train,Y_test=train_test_split(X_scaler,y,test_size=<span class="number">0.3</span>)</span><br><span class="line">AdaBoost = AdaBoostClassifier(n_estimators=<span class="number">100</span>)</span><br><span class="line">AdaBoost.fit(X_train, Y_train)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;准确率:&#x27;</span>,AdaBoost.score(X_test,Y_test))</span><br></pre></td></tr></table></figure>
<pre><code>准确率: 0.8352059925093633
</code></pre>
<p>学习曲线</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> learning_curve</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> ShuffleSplit</span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> GaussianNB</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.rcParams[<span class="string">&#x27;figure.dpi&#x27;</span>] = <span class="number">300</span> <span class="comment">#分辨率</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>] <span class="comment">#用来正常显示中文标签</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span> <span class="comment">#用来正常显示负号</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">plot_learning_curve</span>(<span class="params">estimator, title, X, y, axes=<span class="literal">None</span>, ylim=<span class="literal">None</span>, cv=<span class="literal">None</span>,n_jobs=<span class="literal">None</span>, train_sizes=np.linspace(<span class="params"><span class="number">.1</span>, <span class="number">1.0</span>, <span class="number">5</span></span>)</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> axes <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        _, axes = plt.subplots(<span class="number">1</span>, <span class="number">3</span>, figsize=(<span class="number">20</span>, <span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">    axes[<span class="number">0</span>].set_title(title)</span><br><span class="line">    <span class="keyword">if</span> ylim <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        axes[<span class="number">0</span>].set_ylim(*ylim)</span><br><span class="line">    axes[<span class="number">0</span>].set_xlabel(<span class="string">&quot;训练数据个数&quot;</span>)</span><br><span class="line">    axes[<span class="number">0</span>].set_ylabel(<span class="string">&quot;得分&quot;</span>)</span><br><span class="line"></span><br><span class="line">    train_sizes, train_scores, test_scores, fit_times, _ = \</span><br><span class="line">        learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,</span><br><span class="line">                       train_sizes=train_sizes,</span><br><span class="line">                       return_times=<span class="literal">True</span>)</span><br><span class="line">    train_scores_mean = np.mean(train_scores, axis=<span class="number">1</span>)</span><br><span class="line">    train_scores_std = np.std(train_scores, axis=<span class="number">1</span>)</span><br><span class="line">    test_scores_mean = np.mean(test_scores, axis=<span class="number">1</span>)</span><br><span class="line">    test_scores_std = np.std(test_scores, axis=<span class="number">1</span>)</span><br><span class="line">    fit_times_mean = np.mean(fit_times, axis=<span class="number">1</span>)</span><br><span class="line">    fit_times_std = np.std(fit_times, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 绘制学习曲线</span></span><br><span class="line">    axes[<span class="number">0</span>].grid()</span><br><span class="line">    axes[<span class="number">0</span>].fill_between(train_sizes, train_scores_mean - train_scores_std,</span><br><span class="line">                         train_scores_mean + train_scores_std, alpha=<span class="number">0.1</span>,</span><br><span class="line">                         color=<span class="string">&quot;r&quot;</span>)</span><br><span class="line">    axes[<span class="number">0</span>].fill_between(train_sizes, test_scores_mean - test_scores_std,</span><br><span class="line">                         test_scores_mean + test_scores_std, alpha=<span class="number">0.1</span>,</span><br><span class="line">                         color=<span class="string">&quot;g&quot;</span>)</span><br><span class="line">    axes[<span class="number">0</span>].plot(train_sizes, train_scores_mean, <span class="string">&#x27;o-&#x27;</span>, color=<span class="string">&quot;r&quot;</span>,</span><br><span class="line">                 label=<span class="string">&quot;训练分数&quot;</span>)</span><br><span class="line">    axes[<span class="number">0</span>].plot(train_sizes, test_scores_mean, <span class="string">&#x27;o-&#x27;</span>, color=<span class="string">&quot;g&quot;</span>,</span><br><span class="line">                 label=<span class="string">&quot;交叉验证分数&quot;</span>)</span><br><span class="line">    axes[<span class="number">0</span>].legend(loc=<span class="string">&quot;best&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Plot n_samples vs fit_times</span></span><br><span class="line">    axes[<span class="number">1</span>].grid()</span><br><span class="line">    axes[<span class="number">1</span>].plot(train_sizes, fit_times_mean, <span class="string">&#x27;o-&#x27;</span>)</span><br><span class="line">    axes[<span class="number">1</span>].fill_between(train_sizes, fit_times_mean - fit_times_std,</span><br><span class="line">                         fit_times_mean + fit_times_std, alpha=<span class="number">0.1</span>)</span><br><span class="line">    axes[<span class="number">1</span>].set_xlabel(<span class="string">&quot;训练数据个数&quot;</span>)</span><br><span class="line">    axes[<span class="number">1</span>].set_ylabel(<span class="string">&quot;拟合时间&quot;</span>)</span><br><span class="line">    axes[<span class="number">1</span>].set_title(<span class="string">&quot;模型可拓展性&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 绘制拟合时间与得分</span></span><br><span class="line">    axes[<span class="number">2</span>].grid()</span><br><span class="line">    axes[<span class="number">2</span>].plot(fit_times_mean, test_scores_mean, <span class="string">&#x27;o-&#x27;</span>)</span><br><span class="line">    axes[<span class="number">2</span>].fill_between(fit_times_mean, test_scores_mean - test_scores_std,</span><br><span class="line">                         test_scores_mean + test_scores_std, alpha=<span class="number">0.1</span>)</span><br><span class="line">    axes[<span class="number">2</span>].set_xlabel(<span class="string">&quot;拟合时间&quot;</span>)</span><br><span class="line">    axes[<span class="number">2</span>].set_ylabel(<span class="string">&quot;得分&quot;</span>)</span><br><span class="line">    axes[<span class="number">2</span>].set_title(<span class="string">&quot;模型表现&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> plt</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">title = <span class="string">&quot;学习曲线 (Adaboost)&quot;</span></span><br><span class="line"></span><br><span class="line">cv = ShuffleSplit(n_splits=<span class="number">10</span>, test_size=<span class="number">0.2</span>, random_state=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">plot_learning_curve(AdaBoostClassifier(n_estimators=<span class="number">100</span>), title, X_scaler, y, ylim=(<span class="number">0.7</span>, <span class="number">1.01</span>),cv=cv, n_jobs=<span class="number">4</span>)</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/output_172_1-165310614675873.png" alt="学习曲线"></p>
<h1>无监督学习</h1>
<h2 id="数据处理-2">数据处理</h2>
<p>导入库</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br></pre></td></tr></table></figure>
<p>读取数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df_unsupervised = pd.read_table(<span class="string">&quot;agg.txt&quot;</span>, sep=<span class="string">&#x27;\t&#x27;</span>,engine=<span class="string">&#x27;python&#x27;</span>)</span><br><span class="line">df_unsupervised</span><br></pre></td></tr></table></figure>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x1</th>
      <th>x2</th>
      <th>y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>15.55</td>
      <td>28.65</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>14.90</td>
      <td>27.55</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>14.45</td>
      <td>28.35</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>14.15</td>
      <td>28.80</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>13.75</td>
      <td>28.05</td>
      <td>2</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>783</th>
      <td>7.80</td>
      <td>3.35</td>
      <td>5</td>
    </tr>
    <tr>
      <th>784</th>
      <td>8.05</td>
      <td>2.75</td>
      <td>5</td>
    </tr>
    <tr>
      <th>785</th>
      <td>8.50</td>
      <td>3.25</td>
      <td>5</td>
    </tr>
    <tr>
      <th>786</th>
      <td>8.10</td>
      <td>3.55</td>
      <td>5</td>
    </tr>
    <tr>
      <th>787</th>
      <td>8.15</td>
      <td>4.00</td>
      <td>5</td>
    </tr>
  </tbody>
</table>
<p>788 rows × 3 columns</p>
</div>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df_unsupervised.describe()</span><br></pre></td></tr></table></figure>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x1</th>
      <th>x2</th>
      <th>y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>788.000000</td>
      <td>788.000000</td>
      <td>788.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>19.566815</td>
      <td>14.171764</td>
      <td>3.770305</td>
    </tr>
    <tr>
      <th>std</th>
      <td>9.922042</td>
      <td>8.089683</td>
      <td>1.596305</td>
    </tr>
    <tr>
      <th>min</th>
      <td>3.350000</td>
      <td>1.950000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>11.150000</td>
      <td>7.037500</td>
      <td>2.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>18.225000</td>
      <td>11.725000</td>
      <td>4.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>30.700000</td>
      <td>21.962500</td>
      <td>5.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>36.550000</td>
      <td>29.150000</td>
      <td>7.000000</td>
    </tr>
  </tbody>
</table>
</div>
<p>绘制散点图</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df_unsupervised.plot.scatter(x=<span class="string">&#x27;x1&#x27;</span>,y=<span class="string">&#x27;x2&#x27;</span>,c=<span class="string">&#x27;y&#x27;</span>,colormap=<span class="string">&#x27;viridis&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/output_181_0-165310619839974.png" alt="散点图"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_unsupervised = df_unsupervised[[<span class="string">&#x27;x1&#x27;</span> , <span class="string">&#x27;x2&#x27;</span>]]</span><br><span class="line">Y_unsupervised = df_unsupervised[<span class="string">&#x27;y&#x27;</span>]</span><br></pre></td></tr></table></figure>
<h2 id="K-means聚类">K-means聚类</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">y_unsupervised_pred=KMeans(n_clusters=<span class="number">5</span>,random_state=<span class="number">9</span>).fit_predict(X_unsupervised)</span><br><span class="line">plt.scatter(X_unsupervised[<span class="string">&#x27;x1&#x27;</span>],X_unsupervised[<span class="string">&#x27;x2&#x27;</span>],c=y_unsupervised_pred)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/output_185_0-165310623654875.png" alt="K-means聚类"></p>
<p>轮廓分析</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> silhouette_samples, silhouette_score</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.rcParams[<span class="string">&#x27;figure.dpi&#x27;</span>] = <span class="number">300</span> <span class="comment">#分辨率</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>] <span class="comment">#用来正常显示中文标签</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span> <span class="comment">#用来正常显示负号</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.cm <span class="keyword">as</span> cm</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line">range_n_clusters = np.arange(<span class="number">2</span>,<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> n_clusters <span class="keyword">in</span> range_n_clusters:</span><br><span class="line">    <span class="comment"># Create a subplot with 1 row and 2 columns</span></span><br><span class="line">    fig, (ax1, ax2) = plt.subplots(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">    fig.set_size_inches(<span class="number">18</span>, <span class="number">7</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># The 1st subplot is the silhouette plot</span></span><br><span class="line">    <span class="comment"># The silhouette coefficient can range from -1, 1 but in this example all</span></span><br><span class="line">    <span class="comment"># lie within [-0.1, 1]</span></span><br><span class="line">    ax1.set_xlim([-<span class="number">0.1</span>, <span class="number">1</span>])</span><br><span class="line">    <span class="comment"># The (n_clusters+1)*10 is for inserting blank space between silhouette</span></span><br><span class="line">    <span class="comment"># plots of individual clusters, to demarcate them clearly.</span></span><br><span class="line">    ax1.set_ylim([<span class="number">0</span>, <span class="built_in">len</span>(X) + (n_clusters + <span class="number">1</span>) * <span class="number">10</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Initialize the clusterer with n_clusters value and a random generator</span></span><br><span class="line">    <span class="comment"># seed of 10 for reproducibility.</span></span><br><span class="line">    clusterer = KMeans(n_clusters=n_clusters, random_state=<span class="number">10</span>)</span><br><span class="line">    cluster_labels = clusterer.fit_predict(X_unsupervised)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># The silhouette_score gives the average value for all the samples.</span></span><br><span class="line">    <span class="comment"># This gives a perspective into the density and separation of the formed</span></span><br><span class="line">    <span class="comment"># clusters</span></span><br><span class="line">    silhouette_avg = silhouette_score(X_unsupervised, cluster_labels)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;对于簇数为&quot;</span>, n_clusters,<span class="string">&quot;平均轮廓得分 :&quot;</span>, silhouette_avg)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute the silhouette scores for each sample</span></span><br><span class="line">    sample_silhouette_values = silhouette_samples(X_unsupervised, cluster_labels)</span><br><span class="line"></span><br><span class="line">    y_lower = <span class="number">10</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_clusters):</span><br><span class="line">        <span class="comment"># Aggregate the silhouette scores for samples belonging to</span></span><br><span class="line">        <span class="comment"># cluster i, and sort them</span></span><br><span class="line">        ith_cluster_silhouette_values = \</span><br><span class="line">            sample_silhouette_values[cluster_labels == i]</span><br><span class="line"></span><br><span class="line">        ith_cluster_silhouette_values.sort()</span><br><span class="line"></span><br><span class="line">        size_cluster_i = ith_cluster_silhouette_values.shape[<span class="number">0</span>]</span><br><span class="line">        y_upper = y_lower + size_cluster_i</span><br><span class="line"></span><br><span class="line">        color = cm.nipy_spectral(<span class="built_in">float</span>(i) / n_clusters)</span><br><span class="line">        ax1.fill_betweenx(np.arange(y_lower, y_upper),</span><br><span class="line">                          <span class="number">0</span>, ith_cluster_silhouette_values,</span><br><span class="line">                          facecolor=color, edgecolor=color, alpha=<span class="number">0.7</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Label the silhouette plots with their cluster numbers at the middle</span></span><br><span class="line">        ax1.text(-<span class="number">0.05</span>, y_lower + <span class="number">0.5</span> * size_cluster_i, <span class="built_in">str</span>(i))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Compute the new y_lower for next plot</span></span><br><span class="line">        y_lower = y_upper + <span class="number">10</span>  <span class="comment"># 10 for the 0 samples</span></span><br><span class="line"></span><br><span class="line">    ax1.set_title(<span class="string">&quot;各簇的轮廓图&quot;</span>)</span><br><span class="line">    ax1.set_xlabel(<span class="string">&quot;廓形系数值&quot;</span>)</span><br><span class="line">    ax1.set_ylabel(<span class="string">&quot;簇标签&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># The vertical line for average silhouette score of all the values</span></span><br><span class="line">    ax1.axvline(x=silhouette_avg, color=<span class="string">&quot;red&quot;</span>, linestyle=<span class="string">&quot;--&quot;</span>)</span><br><span class="line"></span><br><span class="line">    ax1.set_yticks([])  <span class="comment"># Clear the yaxis labels / ticks</span></span><br><span class="line">    ax1.set_xticks([-<span class="number">0.1</span>, <span class="number">0</span>, <span class="number">0.2</span>, <span class="number">0.4</span>, <span class="number">0.6</span>, <span class="number">0.8</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2nd Plot showing the actual clusters formed</span></span><br><span class="line">    colors = cm.nipy_spectral(cluster_labels.astype(<span class="built_in">float</span>) / n_clusters)</span><br><span class="line">    ax2.scatter(X_unsupervised[<span class="string">&#x27;x1&#x27;</span>], X_unsupervised[<span class="string">&#x27;x2&#x27;</span>], marker=<span class="string">&#x27;.&#x27;</span>, s=<span class="number">30</span>, lw=<span class="number">0</span>, alpha=<span class="number">0.7</span>,c=colors, edgecolor=<span class="string">&#x27;k&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Labeling the clusters</span></span><br><span class="line">    centers = clusterer.cluster_centers_</span><br><span class="line">    <span class="comment"># Draw white circles at cluster centers</span></span><br><span class="line">    ax2.scatter(centers[:, <span class="number">0</span>], centers[:, <span class="number">1</span>], marker=<span class="string">&#x27;o&#x27;</span>,c=<span class="string">&quot;white&quot;</span>, alpha=<span class="number">1</span>, s=<span class="number">200</span>, edgecolor=<span class="string">&#x27;k&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i, c <span class="keyword">in</span> <span class="built_in">enumerate</span>(centers):</span><br><span class="line">        ax2.scatter(c[<span class="number">0</span>], c[<span class="number">1</span>], marker=<span class="string">&#x27;$%d$&#x27;</span> % i, alpha=<span class="number">1</span>,</span><br><span class="line">                    s=<span class="number">50</span>, edgecolor=<span class="string">&#x27;k&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    ax2.set_title(<span class="string">&quot;聚类数据的可视化。&quot;</span>)</span><br><span class="line">    ax2.set_xlabel(<span class="string">&quot;第一个特征的特征空间&quot;</span>)</span><br><span class="line">    ax2.set_ylabel(<span class="string">&quot;第二个特征的特征空间&quot;</span>)</span><br><span class="line"></span><br><span class="line">    plt.suptitle((<span class="string">&quot;对样本数据进行KMeans聚类的廓形分析&quot;</span></span><br><span class="line">                  <span class="string">&quot;对于簇数为 %d&quot;</span> % n_clusters),</span><br><span class="line">                 fontsize=<span class="number">14</span>, fontweight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<pre><code>对于簇数为 2 平均轮廓得分 : 0.4558185732952947
对于簇数为 3 平均轮廓得分 : 0.5233926629564977
对于簇数为 4 平均轮廓得分 : 0.5236026699214911
对于簇数为 5 平均轮廓得分 : 0.4986983771034953
对于簇数为 6 平均轮廓得分 : 0.5092643403975724
对于簇数为 7 平均轮廓得分 : 0.4809820385173227
对于簇数为 8 平均轮廓得分 : 0.45319390110467783
对于簇数为 9 平均轮廓得分 : 0.4725748945562861
</code></pre>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/output_188_1-165310628544476.png" alt="对于簇数为 2 轮廓分析"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/output_188_2-165310631126977.png" alt="对于簇数为 3 轮廓分析"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/output_188_3-165310632689278.png" alt="对于簇数为 4 轮廓分析"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/output_188_4-165310635130279.png" alt="对于簇数为 5 轮廓分析"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/output_188_5-165310636855880.png" alt="对于簇数为 6 轮廓分析"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/output_188_6-165310638366281.png" alt="对于簇数为 7 轮廓分析"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/output_188_7-165310639688182.png" alt="对于簇数为 8 轮廓分析"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/output_188_8-165310641933283.png" alt="对于簇数为 9 轮廓分析"></p>
<h2 id="DBSCAN聚类">DBSCAN聚类</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> DBSCAN</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">dbs = DBSCAN(eps=<span class="number">3.5</span>, min_samples=<span class="number">50</span>)</span><br><span class="line">dbs.fit(X_unsupervised)</span><br><span class="line">result = dbs.fit_predict(X_unsupervised)</span><br><span class="line">plt.figure()</span><br><span class="line">plt.scatter(X_unsupervised[<span class="string">&#x27;x1&#x27;</span>],X_unsupervised[<span class="string">&#x27;x2&#x27;</span>], c=result)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/output_191_0-165310643367184.png" alt="DBSCAN聚类"></p>
<p>寻找最优参数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">rs= []</span><br><span class="line">eps = np.arange(<span class="number">0.2</span>,<span class="number">5</span>,<span class="number">0.1</span>)</span><br><span class="line">min_samples=np.arange(<span class="number">2</span>,<span class="number">20</span>,<span class="number">1</span>)</span><br><span class="line">best_score=<span class="number">0</span></span><br><span class="line">best_score_eps=<span class="number">0</span></span><br><span class="line">best_score_min_samples=<span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> eps:</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> min_samples:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            db = DBSCAN(eps=i, min_samples=j).fit(X_unsupervised)</span><br><span class="line">            labels= db.labels_</span><br><span class="line">            k=metrics.silhouette_score(X_unsupervised,labels)</span><br><span class="line">            raito = <span class="built_in">len</span>(labels[labels[:] == -<span class="number">1</span>]) / <span class="built_in">len</span>(labels)</span><br><span class="line">            n_clusters_ = <span class="built_in">len</span>(<span class="built_in">set</span>(labels)) - (<span class="number">1</span> <span class="keyword">if</span> -<span class="number">1</span> <span class="keyword">in</span> labels <span class="keyword">else</span> <span class="number">0</span>)</span><br><span class="line">            rs.append([i,j,k,raito,n_clusters_])</span><br><span class="line">            <span class="keyword">if</span> k&gt;best_score:</span><br><span class="line">                best_score=k</span><br><span class="line">                best_score_eps=i</span><br><span class="line">                best_score_min_samples=j</span><br><span class="line"></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                db=<span class="string">&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            db=<span class="string">&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">rs= pd.DataFrame(rs)</span><br><span class="line">rs.columns=[<span class="string">&#x27;eps&#x27;</span>,<span class="string">&#x27;min_samples&#x27;</span>,<span class="string">&#x27;score&#x27;</span>,<span class="string">&#x27;raito&#x27;</span>,<span class="string">&#x27;n_clusters&#x27;</span>]</span><br><span class="line">sns.relplot(x=<span class="string">&quot;eps&quot;</span>,y=<span class="string">&quot;min_samples&quot;</span>, size=<span class="string">&#x27;score&#x27;</span>,data=rs)</span><br><span class="line">sns.relplot(x=<span class="string">&quot;eps&quot;</span>,y=<span class="string">&quot;min_samples&quot;</span>, size=<span class="string">&#x27;raito&#x27;</span>,data=rs)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;最优得分&#x27;</span>,best_score,<span class="string">&#x27;\n最优得分_eps&#x27;</span>,best_score_eps,<span class="string">&#x27;\n最优得分_min_samples&#x27;</span>,best_score_min_samples)</span><br></pre></td></tr></table></figure>
<pre><code>最优得分 0.4868290825347166 
最优得分_eps 1.3000000000000003 
最优得分_min_samples 7
</code></pre>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/output_193_1-165310645642385.png" alt="得分图"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/output_193_2-165310646191186.png" alt="得分图"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">best_model = DBSCAN(eps=best_score_eps, min_samples=best_score_min_samples)</span><br><span class="line">best_model.fit(X_unsupervised)</span><br><span class="line">result = best_model.fit_predict(X_unsupervised)</span><br><span class="line">plt.figure()</span><br><span class="line">plt.scatter(X_unsupervised[<span class="string">&#x27;x1&#x27;</span>],X_unsupervised[<span class="string">&#x27;x2&#x27;</span>], c=result)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/output_194_0-165310648044587.png" alt="DBSCAN聚类"></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://example.com">花瓶</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/">http://example.com/2022/05/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">花瓶里的芝士不收费</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a><a class="post-meta__tags" href="/tags/Python/">Python</a><a class="post-meta__tags" href="/tags/sklearn/">sklearn</a></div><div class="post_share"><div class="social-share" data-image="/img/The_Nightwatch.jpg" data-sites="qq,wechat,weibo"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/07/03/%E5%89%8D%E7%AB%AF%E5%AD%A6%E4%B9%A0/" title="前端学习"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/img/Athens.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">前端学习</div></div></a></div><div class="next-post pull-right"><a href="/2022/04/23/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90/" title="数值分析"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/img/Starry_Night.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">数值分析</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2022/10/08/R%E8%AF%AD%E8%A8%80%E5%AD%A6%E4%B9%A0/" title="R语言学习"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/img/Claude_Monet.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-10-08</div><div class="title">R语言学习</div></div></a></div><div><a href="/2022/04/23/%E6%95%B0%E6%8D%AE%E5%BA%93/" title="数据库"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/img/Romeo_and_Juliet.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-04-23</div><div class="title">数据库</div></div></a></div></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/img/John_King.webp" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">花瓶</div><div class="author-info__description">简简单单的小花瓶~</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">15</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">18</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/robust-vase"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/robust-vase" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:robustvase@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="https://www.zhihu.com/people/yu-xia-si-can-hong" target="_blank" title="zhihu"><i class="fab fa-zhihu"></i></a><a class="social-icon" href="https://space.bilibili.com/197525661" target="_blank" title="bilibili"><i class="fab fa-bilibili"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content"><center style="color: var(--theme-color)">
  <b><span style="font-size: 20px">花瓶简介</span><br>
  从<span style="font-size: 16px">计算数学</span>转到<span style="font-size: 16px">心理学</span>的花瓶～<br>
  时不时发布算法👨🏻‍💻相关笔记<br>
  或许是单细胞测序🧬内容<br>
  👋关注花瓶的都是现实中的朋友啦～<br>
  🚀<span style="font-size: 16px">花瓶持续更新～</span>🚀<br>
  </b>
</center>
</div><div id="welcome-info"></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%86%99%E5%9C%A8%E5%89%8D%E9%9D%A2-2"><span class="toc-number">1.1.</span> <span class="toc-text">写在前面</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B7%A5%E5%85%B7"><span class="toc-number">1.2.</span> <span class="toc-text">工具</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%85%8D%E7%BD%AEPython%E7%8E%AF%E5%A2%83"><span class="toc-number">1.3.</span> <span class="toc-text">配置Python环境</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">数据预处理与数据分析</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AF%BC%E5%85%A5%E5%BA%93%E4%B8%8E%E6%95%B0%E6%8D%AE"><span class="toc-number">2.1.</span> <span class="toc-text">导入库与数据</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86"><span class="toc-number">2.2.</span> <span class="toc-text">数据处理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%A7%E5%88%AB%E5%A4%84%E7%90%86"><span class="toc-number">2.2.1.</span> <span class="toc-text">性别处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A7%93%E5%90%8D%E5%A4%84%E7%90%86"><span class="toc-number">2.2.2.</span> <span class="toc-text">姓名处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%88%B9%E7%A5%A8%E7%BC%96%E5%8F%B7%E5%A4%84%E7%90%86"><span class="toc-number">2.2.3.</span> <span class="toc-text">船票编号处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B9%98%E5%AE%A2%E4%B9%98%E8%88%B9%E7%A0%81%E5%A4%B4%E5%A4%84%E7%90%86"><span class="toc-number">2.2.4.</span> <span class="toc-text">乘客乘船码头处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B9%B4%E9%BE%84%E5%A4%84%E7%90%86"><span class="toc-number">2.2.5.</span> <span class="toc-text">年龄处理</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90"><span class="toc-number">2.3.</span> <span class="toc-text">数据分析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%9F%E8%AE%A1%E9%87%8F%E5%88%86%E6%9E%90"><span class="toc-number">2.3.1.</span> <span class="toc-text">统计量分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9B%BE%E8%A1%A8%E5%88%86%E6%9E%90"><span class="toc-number">2.3.2.</span> <span class="toc-text">图表分析</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">分类模型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.1.</span> <span class="toc-text">决策树模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-number">3.2.</span> <span class="toc-text">人工神经网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA"><span class="toc-number">3.3.</span> <span class="toc-text">支持向量机</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%87%AA%E9%80%82%E5%BA%94%E6%8F%90%E5%8D%87%E6%B3%95"><span class="toc-number">3.4.</span> <span class="toc-text">自适应提升法</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">4.</span> <span class="toc-text">无监督学习</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86-2"><span class="toc-number">4.1.</span> <span class="toc-text">数据处理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#K-means%E8%81%9A%E7%B1%BB"><span class="toc-number">4.2.</span> <span class="toc-text">K-means聚类</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#DBSCAN%E8%81%9A%E7%B1%BB"><span class="toc-number">4.3.</span> <span class="toc-text">DBSCAN聚类</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/06/18/%E5%BF%83%E7%90%86%E7%BB%9F%E8%AE%A1/" title="心理统计"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/img/Starry_Night.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="心理统计"/></a><div class="content"><a class="title" href="/2024/06/18/%E5%BF%83%E7%90%86%E7%BB%9F%E8%AE%A1/" title="心理统计">心理统计</a><time datetime="2024-06-18T01:05:58.000Z" title="发表于 2024-06-18 09:05:58">2024-06-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/03/07/%E5%9B%BE%E8%AE%BA/" title="图论"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/img/Women_of_Amphissa.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="图论"/></a><div class="content"><a class="title" href="/2024/03/07/%E5%9B%BE%E8%AE%BA/" title="图论">图论</a><time datetime="2024-03-07T10:12:27.000Z" title="发表于 2024-03-07 18:12:27">2024-03-07</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/07/31/%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95/" title="高级数据结构"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/img/The_Nightwatch.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="高级数据结构"/></a><div class="content"><a class="title" href="/2023/07/31/%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95/" title="高级数据结构">高级数据结构</a><time datetime="2023-07-31T02:53:35.000Z" title="发表于 2023-07-31 10:53:35">2023-07-31</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/01/29/%E6%8E%92%E5%BA%8F%E9%80%89%E6%8B%A9%E7%AE%97%E6%B3%95/" title="排序选择算法"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/img/Figure_in_a_Room.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="排序选择算法"/></a><div class="content"><a class="title" href="/2023/01/29/%E6%8E%92%E5%BA%8F%E9%80%89%E6%8B%A9%E7%AE%97%E6%B3%95/" title="排序选择算法">排序选择算法</a><time datetime="2023-01-29T09:59:49.000Z" title="发表于 2023-01-29 17:59:49">2023-01-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/10/19/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" title="数据结构"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/lazyload.gif" data-original="/img/Starry_Night.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="数据结构"/></a><div class="content"><a class="title" href="/2022/10/19/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" title="数据结构">数据结构</a><time datetime="2022-10-19T04:20:06.000Z" title="发表于 2022-10-19 12:20:06">2022-10-19</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2024 By 花瓶</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js"></script><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script><script>function loadGitalk () {
  function initGitalk () {
    var gitalk = new Gitalk(Object.assign({
      clientID: 'e19706903ff8a3f54196',
      clientSecret: '6854f9b2fb4f13d47055fbbf869e0e815516840f',
      repo: 'robust-vase.github.io',
      owner: 'robust-vase',
      admin: ['robust-vase'],
      id: '33f44c29d4e53b485e144cee0e906e4c',
      updateCountCallback: commentCount
    },null))

    gitalk.render('gitalk-container')
  }

  if (typeof Gitalk === 'function') initGitalk()
  else {
    getCSS('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css')
    getScript('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.js').then(initGitalk)
  }
}

function commentCount(n){
  let isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
  if (isCommentCount) {
    isCommentCount.textContent= n
  }
}

if ('Gitalk' === 'Gitalk' || !false) {
  if (false) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
  else loadGitalk()
} else {
  function loadOtherComment () {
    loadGitalk()
  }
}</script></div><script async src="/js/title.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-show-text" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-show-text.min.js" data-mobile="false" data-text="富强,民主,文明,和谐,自由,文明,平等,公正,法制,爱国,敬业,诚信,友善" data-fontsize="15px" data-random="false" async="async"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div class="no-result" id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div><!-- hexo injector body_end start --><script data-pjax>
  function butterfly_footer_beautify_injector_config(){
    var parent_div_git = document.getElementById('footer-wrap');
    var item_html = '<div id="workboard"></div>';
    console.log('已挂载butterfly_footer_beautify')
    parent_div_git.insertAdjacentHTML("beforeend",item_html)
    }
  var elist = 'null'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_footer_beautify_injector_config();
  }
  else if (epage === cpage){
    butterfly_footer_beautify_injector_config();
  }
  </script><script async src="/js/footer.js"></script><!-- hexo injector body_end end --><script>
            window.imageLazyLoadSetting = {
                isSPA: false,
                preloadRatio: 1,
                processImages: null,
            };
        </script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(e.href.match(t)||e.href.match(r))&&(e.href=a.dataset.original)})});</script><script>!function(n){n.imageLazyLoadSetting.processImages=o;var e=n.imageLazyLoadSetting.isSPA,i=n.imageLazyLoadSetting.preloadRatio||1,r=Array.prototype.slice.call(document.querySelectorAll("img[data-original]"));function o(){e&&(r=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")));for(var t,a=0;a<r.length;a++)0<=(t=(t=r[a]).getBoundingClientRect()).bottom&&0<=t.left&&t.top<=(n.innerHeight*i||document.documentElement.clientHeight*i)&&function(){var t,e,n,i,o=r[a];t=o,e=function(){r=r.filter(function(t){return o!==t})},n=new Image,i=t.getAttribute("data-original"),n.onload=function(){t.src=i,e&&e()},t.src!==i&&(n.src=i)}()}o(),n.addEventListener("scroll",function(){var t,e;t=o,e=n,clearTimeout(t.tId),t.tId=setTimeout(function(){t.call(e)},500)})}(this);</script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/assets/koharu.model.json"},"display":{"position":"left","width":150,"height":300},"mobile":{"show":true,"scale":0.5},"react":{"opacityDefault":0.7,"opacityOnHover":0.8},"log":false});</script></body></html>